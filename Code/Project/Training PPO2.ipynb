{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host 127.0.0.1 at port 49506 ...\n",
      "Client connected to server [OK]\n",
      "Connecting to host 127.0.0.1 at port 49509 ...\n",
      "Client connected to server [OK]\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e5add0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e5add0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e5add0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e5add0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e75f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e75f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e75f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x143e75f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010100189 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -10.1        |\n",
      "| fps                | 28           |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 1.7907311    |\n",
      "| policy_loss        | -0.006978605 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 2.48e-05     |\n",
      "| total_timesteps    | 128          |\n",
      "| value_loss         | 0.044520576  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0012131056 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 1.19e-07     |\n",
      "| fps                | 30           |\n",
      "| n_updates          | 2            |\n",
      "| policy_entropy     | 1.7850742    |\n",
      "| policy_loss        | -0.008084659 |\n",
      "| serial_timesteps   | 256          |\n",
      "| time_elapsed       | 4.55         |\n",
      "| total_timesteps    | 256          |\n",
      "| value_loss         | 0.03978361   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00046024416 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 1.7802688     |\n",
      "| policy_loss        | -0.001585457  |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 8.79          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 0.0006358777  |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=500, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 723.20 +/- 695.51\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006297871 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 1            |\n",
      "| n_updates          | 4            |\n",
      "| policy_entropy     | 1.7832521    |\n",
      "| policy_loss        | -0.0039901   |\n",
      "| serial_timesteps   | 512          |\n",
      "| time_elapsed       | 13           |\n",
      "| total_timesteps    | 512          |\n",
      "| value_loss         | 0.015787156  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014731216 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 29           |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 1.7763422    |\n",
      "| policy_loss        | -0.009808993 |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 129          |\n",
      "| total_timesteps    | 640          |\n",
      "| value_loss         | 0.07296756   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00022421409 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 6             |\n",
      "| policy_entropy     | 1.7612748     |\n",
      "| policy_loss        | 0.0012610531  |\n",
      "| serial_timesteps   | 768           |\n",
      "| time_elapsed       | 133           |\n",
      "| total_timesteps    | 768           |\n",
      "| value_loss         | 0.00029586462 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011387634  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 7             |\n",
      "| policy_entropy     | 1.7693875     |\n",
      "| policy_loss        | -0.005214551  |\n",
      "| serial_timesteps   | 896           |\n",
      "| time_elapsed       | 137           |\n",
      "| total_timesteps    | 896           |\n",
      "| value_loss         | 5.5453125e-05 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 568.80 +/- 729.35\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00045256555 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 1.7792445     |\n",
      "| policy_loss        | -0.0013387077 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 141           |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 0.022956131   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00049616495 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.07e-06      |\n",
      "| fps                | 32            |\n",
      "| n_updates          | 9             |\n",
      "| policy_entropy     | 1.7830828     |\n",
      "| policy_loss        | -0.0017018111 |\n",
      "| serial_timesteps   | 1152          |\n",
      "| time_elapsed       | 229           |\n",
      "| total_timesteps    | 1152          |\n",
      "| value_loss         | 0.00028672937 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00047355526 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 32            |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 1.7835441     |\n",
      "| policy_loss        | -0.0049723117 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 233           |\n",
      "| total_timesteps    | 1280          |\n",
      "| value_loss         | 0.00018060312 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00048510518 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 32            |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 1.780685      |\n",
      "| policy_loss        | -0.0016573339 |\n",
      "| serial_timesteps   | 1408          |\n",
      "| time_elapsed       | 237           |\n",
      "| total_timesteps    | 1408          |\n",
      "| value_loss         | 0.00013752871 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=1500, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 836.00 +/- 700.43\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00012062746  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 5.96e-08       |\n",
      "| fps                | 0              |\n",
      "| n_updates          | 12             |\n",
      "| policy_entropy     | 1.7780023      |\n",
      "| policy_loss        | -0.0015818495  |\n",
      "| serial_timesteps   | 1536           |\n",
      "| time_elapsed       | 241            |\n",
      "| total_timesteps    | 1536           |\n",
      "| value_loss         | 0.000115134404 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00049985014 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 1.783215      |\n",
      "| policy_loss        | -0.0019946224 |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 380           |\n",
      "| total_timesteps    | 1664          |\n",
      "| value_loss         | 0.021186676   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0003667658 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 27           |\n",
      "| n_updates          | 14           |\n",
      "| policy_entropy     | 1.785147     |\n",
      "| policy_loss        | -0.003092974 |\n",
      "| serial_timesteps   | 1792         |\n",
      "| time_elapsed       | 384          |\n",
      "| total_timesteps    | 1792         |\n",
      "| value_loss         | 0.03921365   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007036162  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 15            |\n",
      "| policy_entropy     | 1.78444       |\n",
      "| policy_loss        | -0.0054942756 |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 389           |\n",
      "| total_timesteps    | 1920          |\n",
      "| value_loss         | 3.842911e-05  |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 452.80 +/- 468.65\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007591001  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 1.7817322     |\n",
      "| policy_loss        | -0.004025873  |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 394           |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 2.6863936e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00068960886 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 1.7723417     |\n",
      "| policy_loss        | -0.0024439914 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 474           |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 1.7903516e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00032048952  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 1.35e-05       |\n",
      "| fps                | 27             |\n",
      "| n_updates          | 18             |\n",
      "| policy_entropy     | 1.7641379      |\n",
      "| policy_loss        | -0.00048694364 |\n",
      "| serial_timesteps   | 2304           |\n",
      "| time_elapsed       | 478            |\n",
      "| total_timesteps    | 2304           |\n",
      "| value_loss         | 0.036722597    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00031960476 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 1.7613014     |\n",
      "| policy_loss        | -0.0025280607 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 483           |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 0.0006405618  |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=2500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 676.80 +/- 399.55\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012243263 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 1.7632393     |\n",
      "| policy_loss        | 0.0009597379  |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 487           |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 0.015504038   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.3922835e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 21            |\n",
      "| policy_entropy     | 1.7609438     |\n",
      "| policy_loss        | -0.0005038532 |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 604           |\n",
      "| total_timesteps    | 2688          |\n",
      "| value_loss         | 0.014237751   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00021361987 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 1.763756      |\n",
      "| policy_loss        | -0.0015284556 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 608           |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 0.00040434784 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016620755  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 1.7733549     |\n",
      "| policy_loss        | -0.014045631  |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 613           |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 0.00046931996 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 685.60 +/- 387.14\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015138104  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 2.91e-05      |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 24            |\n",
      "| policy_entropy     | 1.7870669     |\n",
      "| policy_loss        | -0.005596853  |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 617           |\n",
      "| total_timesteps    | 3072          |\n",
      "| value_loss         | 0.00094841263 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008553046  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 1.7904179     |\n",
      "| policy_loss        | -0.0056852135 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 736           |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 0.018492503   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000495258   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 1.7867169     |\n",
      "| policy_loss        | -0.0005841075 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 741           |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 0.01858998    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017308617 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 1.7832475     |\n",
      "| policy_loss        | -0.0015049414 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 745           |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 0.00030040042 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=3500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 330.40 +/- 132.20\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015070145 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 1.7806301     |\n",
      "| policy_loss        | 0.00017517759 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 750           |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 0.00022169917 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00022478428 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 1.7799075     |\n",
      "| policy_loss        | -0.0013140689 |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 810           |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 0.000184225   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004889327 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 28           |\n",
      "| n_updates          | 30           |\n",
      "| policy_entropy     | 1.7815417    |\n",
      "| policy_loss        | -0.004984156 |\n",
      "| serial_timesteps   | 3840         |\n",
      "| time_elapsed       | 814          |\n",
      "| total_timesteps    | 3840         |\n",
      "| value_loss         | 0.0001506174 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005044705  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 1.7749429     |\n",
      "| policy_loss        | -0.0033555476 |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 819           |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 0.018787362   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 469.60 +/- 439.01\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016747735 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 1.772186      |\n",
      "| policy_loss        | 0.0018546898  |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 823           |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 0.00020917009 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000367911   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 6.26e-06      |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 1.7685297     |\n",
      "| policy_loss        | -0.0023602406 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 906           |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 0.00569428    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015246887  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 1.7511916     |\n",
      "| policy_loss        | -0.0089479145 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 910           |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 0.00044809244 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006158979  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 35            |\n",
      "| policy_entropy     | 1.7268422     |\n",
      "| policy_loss        | -0.0011449975 |\n",
      "| serial_timesteps   | 4480          |\n",
      "| time_elapsed       | 915           |\n",
      "| total_timesteps    | 4480          |\n",
      "| value_loss         | 0.00027640205 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=4500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 495.20 +/- 145.84\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010253409  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 1.7386755     |\n",
      "| policy_loss        | -0.005781978  |\n",
      "| serial_timesteps   | 4608          |\n",
      "| time_elapsed       | 919           |\n",
      "| total_timesteps    | 4608          |\n",
      "| value_loss         | 0.00024830463 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002187503   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 37            |\n",
      "| policy_entropy     | 1.7645983     |\n",
      "| policy_loss        | -0.009829844  |\n",
      "| serial_timesteps   | 4736          |\n",
      "| time_elapsed       | 1.01e+03      |\n",
      "| total_timesteps    | 4736          |\n",
      "| value_loss         | 0.00017540218 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006381165  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 1.7799163     |\n",
      "| policy_loss        | -0.0032045892 |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 1.01e+03      |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 0.0001632143  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038830924 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 1.7851138     |\n",
      "| policy_loss        | -0.0019295656 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 1.02e+03      |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 0.00012791985 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 798.40 +/- 309.78\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018654243 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 1.7866714     |\n",
      "| policy_loss        | -0.001216841  |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 1.02e+03      |\n",
      "| total_timesteps    | 5120          |\n",
      "| value_loss         | 0.11434546    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00043233973 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 29            |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 1.7830476     |\n",
      "| policy_loss        | -0.003385643  |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 1.16e+03      |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 0.00010711229 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00028090362 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-07      |\n",
      "| fps                | 31            |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 1.7765832     |\n",
      "| policy_loss        | -0.0006811636 |\n",
      "| serial_timesteps   | 5376          |\n",
      "| time_elapsed       | 1.16e+03      |\n",
      "| total_timesteps    | 5376          |\n",
      "| value_loss         | 9.751496e-06  |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=5500, episode_reward=1.40 +/- 2.06\n",
      "Episode length: 1094.40 +/- 824.51\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00044372847 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 43            |\n",
      "| policy_entropy     | 1.7719015     |\n",
      "| policy_loss        | -0.002541398  |\n",
      "| serial_timesteps   | 5504          |\n",
      "| time_elapsed       | 1.17e+03      |\n",
      "| total_timesteps    | 5504          |\n",
      "| value_loss         | 0.097509705   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015753479 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 29            |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 1.7661268     |\n",
      "| policy_loss        | -0.0007060664 |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 1.34e+03      |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 0.001024456   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0008871545  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 29            |\n",
      "| n_updates          | 45            |\n",
      "| policy_entropy     | 1.7684149     |\n",
      "| policy_loss        | -0.007270351  |\n",
      "| serial_timesteps   | 5760          |\n",
      "| time_elapsed       | 1.34e+03      |\n",
      "| total_timesteps    | 5760          |\n",
      "| value_loss         | 8.8312336e-05 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0009952171 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 29           |\n",
      "| n_updates          | 46           |\n",
      "| policy_entropy     | 1.7614136    |\n",
      "| policy_loss        | -0.007927777 |\n",
      "| serial_timesteps   | 5888         |\n",
      "| time_elapsed       | 1.35e+03     |\n",
      "| total_timesteps    | 5888         |\n",
      "| value_loss         | 6.060559e-05 |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=2.40 +/- 2.87\n",
      "Episode length: 1264.80 +/- 902.07\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010628087  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 1.7654837     |\n",
      "| policy_loss        | 0.00011942978 |\n",
      "| serial_timesteps   | 6016          |\n",
      "| time_elapsed       | 1.35e+03      |\n",
      "| total_timesteps    | 6016          |\n",
      "| value_loss         | 0.0001822166  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00033923247 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 1.771506      |\n",
      "| policy_loss        | -0.004059052  |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 1.56e+03      |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 0.07989262    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010479941  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 1.7722025     |\n",
      "| policy_loss        | -0.0050048046 |\n",
      "| serial_timesteps   | 6272          |\n",
      "| time_elapsed       | 1.56e+03      |\n",
      "| total_timesteps    | 6272          |\n",
      "| value_loss         | 0.0010970314  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00050964043 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 1.778425      |\n",
      "| policy_loss        | -0.002817225  |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 1.56e+03      |\n",
      "| total_timesteps    | 6400          |\n",
      "| value_loss         | 0.00011729248 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=6500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 532.00 +/- 246.10\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002453698  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 1.781143      |\n",
      "| policy_loss        | 0.00069620076 |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 1.57e+03      |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 0.11551792    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016112486  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 52            |\n",
      "| policy_entropy     | 1.771648      |\n",
      "| policy_loss        | -0.010629847  |\n",
      "| serial_timesteps   | 6656          |\n",
      "| time_elapsed       | 1.66e+03      |\n",
      "| total_timesteps    | 6656          |\n",
      "| value_loss         | 0.00017385778 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0017764696  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 1.7452635     |\n",
      "| policy_loss        | -0.0043431753 |\n",
      "| serial_timesteps   | 6784          |\n",
      "| time_elapsed       | 1.67e+03      |\n",
      "| total_timesteps    | 6784          |\n",
      "| value_loss         | 0.11439449    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00036428074 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 54            |\n",
      "| policy_entropy     | 1.7251006     |\n",
      "| policy_loss        | 0.00012172497 |\n",
      "| serial_timesteps   | 6912          |\n",
      "| time_elapsed       | 1.67e+03      |\n",
      "| total_timesteps    | 6912          |\n",
      "| value_loss         | 0.037132338   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 724.80 +/- 649.76\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003158997  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 55            |\n",
      "| policy_entropy     | 1.7216636     |\n",
      "| policy_loss        | -0.002050089  |\n",
      "| serial_timesteps   | 7040          |\n",
      "| time_elapsed       | 1.68e+03      |\n",
      "| total_timesteps    | 7040          |\n",
      "| value_loss         | 0.00024994588 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00031633116 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 56            |\n",
      "| policy_entropy     | 1.7137349     |\n",
      "| policy_loss        | 0.00031366292 |\n",
      "| serial_timesteps   | 7168          |\n",
      "| time_elapsed       | 1.8e+03       |\n",
      "| total_timesteps    | 7168          |\n",
      "| value_loss         | 0.02301385    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011556763  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 57            |\n",
      "| policy_entropy     | 1.6928805     |\n",
      "| policy_loss        | -0.008380258  |\n",
      "| serial_timesteps   | 7296          |\n",
      "| time_elapsed       | 1.81e+03      |\n",
      "| total_timesteps    | 7296          |\n",
      "| value_loss         | 0.00016998837 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0023303635 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 27           |\n",
      "| n_updates          | 58           |\n",
      "| policy_entropy     | 1.6429609    |\n",
      "| policy_loss        | -0.007130347 |\n",
      "| serial_timesteps   | 7424         |\n",
      "| time_elapsed       | 1.81e+03     |\n",
      "| total_timesteps    | 7424         |\n",
      "| value_loss         | 0.023203168  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=7500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 256.80 +/- 66.13\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00046691543 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 1.5926051     |\n",
      "| policy_loss        | 0.0014761761  |\n",
      "| serial_timesteps   | 7552          |\n",
      "| time_elapsed       | 1.82e+03      |\n",
      "| total_timesteps    | 7552          |\n",
      "| value_loss         | 0.029410683   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005286528  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 60            |\n",
      "| policy_entropy     | 1.5915906     |\n",
      "| policy_loss        | -0.0058072265 |\n",
      "| serial_timesteps   | 7680          |\n",
      "| time_elapsed       | 1.86e+03      |\n",
      "| total_timesteps    | 7680          |\n",
      "| value_loss         | 0.011440406   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0020511416 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 28           |\n",
      "| n_updates          | 61           |\n",
      "| policy_entropy     | 1.6069419    |\n",
      "| policy_loss        | -0.008952515 |\n",
      "| serial_timesteps   | 7808         |\n",
      "| time_elapsed       | 1.87e+03     |\n",
      "| total_timesteps    | 7808         |\n",
      "| value_loss         | 0.0008382394 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.005088058  |\n",
      "| clipfrac           | 0.03125      |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 28           |\n",
      "| n_updates          | 62           |\n",
      "| policy_entropy     | 1.672827     |\n",
      "| policy_loss        | -0.012751944 |\n",
      "| serial_timesteps   | 7936         |\n",
      "| time_elapsed       | 1.87e+03     |\n",
      "| total_timesteps    | 7936         |\n",
      "| value_loss         | 0.0005525063 |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 407.20 +/- 340.46\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0009804649   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 1              |\n",
      "| n_updates          | 63             |\n",
      "| policy_entropy     | 1.6992074      |\n",
      "| policy_loss        | -0.00075173704 |\n",
      "| serial_timesteps   | 8064           |\n",
      "| time_elapsed       | 1.88e+03       |\n",
      "| total_timesteps    | 8064           |\n",
      "| value_loss         | 0.00040997422  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00066485343 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 1.689353      |\n",
      "| policy_loss        | -0.0034856335 |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 1.95e+03      |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 0.00023527973 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00075606955 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 65            |\n",
      "| policy_entropy     | 1.6709135     |\n",
      "| policy_loss        | -0.003590965  |\n",
      "| serial_timesteps   | 8320          |\n",
      "| time_elapsed       | 1.95e+03      |\n",
      "| total_timesteps    | 8320          |\n",
      "| value_loss         | 0.00015681898 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039216937 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 28            |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 1.6652182     |\n",
      "| policy_loss        | -5.057431e-05 |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 1.96e+03      |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 8.014014e-05  |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=8500, episode_reward=4.00 +/- 1.90\n",
      "Episode length: 1495.20 +/- 621.10\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00058947486 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 67            |\n",
      "| policy_entropy     | 1.6835074     |\n",
      "| policy_loss        | -0.0010558486 |\n",
      "| serial_timesteps   | 8576          |\n",
      "| time_elapsed       | 1.96e+03      |\n",
      "| total_timesteps    | 8576          |\n",
      "| value_loss         | 0.022519466   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00029717787  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 28             |\n",
      "| n_updates          | 68             |\n",
      "| policy_entropy     | 1.7009747      |\n",
      "| policy_loss        | -0.00018129207 |\n",
      "| serial_timesteps   | 8704           |\n",
      "| time_elapsed       | 2.22e+03       |\n",
      "| total_timesteps    | 8704           |\n",
      "| value_loss         | 0.00023905901  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00018745437  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 27             |\n",
      "| n_updates          | 69             |\n",
      "| policy_entropy     | 1.7160584      |\n",
      "| policy_loss        | -0.00045679032 |\n",
      "| serial_timesteps   | 8832           |\n",
      "| time_elapsed       | 2.22e+03       |\n",
      "| total_timesteps    | 8832           |\n",
      "| value_loss         | 0.0002511037   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.9293666e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 1.7202897     |\n",
      "| policy_loss        | -3.116764e-05 |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 2.23e+03      |\n",
      "| total_timesteps    | 8960          |\n",
      "| value_loss         | 0.00017245681 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=3.60 +/- 1.62\n",
      "Episode length: 1493.60 +/- 648.22\n",
      "--------------------------------------\n",
      "| approxkl           | 0.001431743   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 71            |\n",
      "| policy_entropy     | 1.6986554     |\n",
      "| policy_loss        | -0.012441318  |\n",
      "| serial_timesteps   | 9088          |\n",
      "| time_elapsed       | 2.23e+03      |\n",
      "| total_timesteps    | 9088          |\n",
      "| value_loss         | 0.00011603061 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015167145  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 31            |\n",
      "| n_updates          | 72            |\n",
      "| policy_entropy     | 1.6486897     |\n",
      "| policy_loss        | -0.0019123338 |\n",
      "| serial_timesteps   | 9216          |\n",
      "| time_elapsed       | 2.46e+03      |\n",
      "| total_timesteps    | 9216          |\n",
      "| value_loss         | 3.5078734e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005159491  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -2.38e-07     |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 1.6176144     |\n",
      "| policy_loss        | -0.0030329756 |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 2.47e+03      |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 3.2594337e-05 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.002283604  |\n",
      "| clipfrac           | 0.009765625  |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 30           |\n",
      "| n_updates          | 74           |\n",
      "| policy_entropy     | 1.6389564    |\n",
      "| policy_loss        | -0.010857297 |\n",
      "| serial_timesteps   | 9472         |\n",
      "| time_elapsed       | 2.47e+03     |\n",
      "| total_timesteps    | 9472         |\n",
      "| value_loss         | 1.857053e-05 |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=9500, episode_reward=3.40 +/- 2.33\n",
      "Episode length: 1648.00 +/- 704.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002887204  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 1.688775      |\n",
      "| policy_loss        | 0.0032748792  |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 2.48e+03      |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 1.4615364e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004300439  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 31            |\n",
      "| n_updates          | 76            |\n",
      "| policy_entropy     | 1.6679205     |\n",
      "| policy_loss        | -0.0004417227 |\n",
      "| serial_timesteps   | 9728          |\n",
      "| time_elapsed       | 2.72e+03      |\n",
      "| total_timesteps    | 9728          |\n",
      "| value_loss         | 1.0551968e-05 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.000984103   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 31            |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 1.6365807     |\n",
      "| policy_loss        | -0.006442819  |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 2.73e+03      |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 4.9145897e-06 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00286873   |\n",
      "| clipfrac           | 0.009765625  |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 30           |\n",
      "| n_updates          | 78           |\n",
      "| policy_entropy     | 1.5679121    |\n",
      "| policy_loss        | -0.011299995 |\n",
      "| serial_timesteps   | 9984         |\n",
      "| time_elapsed       | 2.73e+03     |\n",
      "| total_timesteps    | 9984         |\n",
      "| value_loss         | 4.376489e-06 |\n",
      "-------------------------------------\n",
      "Connecting to host 127.0.0.1 at port 49549 ...\n",
      "Client connected to server [OK]\n",
      "Eval num_timesteps=16, episode_reward=4.60 +/- 2.80\n",
      "Episode length: 1700.00 +/- 600.00\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002182052   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -6.07         |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 1.4754165     |\n",
      "| policy_loss        | -0.004478734  |\n",
      "| serial_timesteps   | 128           |\n",
      "| time_elapsed       | 6.29e-05      |\n",
      "| total_timesteps    | 128           |\n",
      "| value_loss         | 0.00026747727 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00020441295  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 30             |\n",
      "| n_updates          | 2              |\n",
      "| policy_entropy     | 1.4213549      |\n",
      "| policy_loss        | -0.00085149636 |\n",
      "| serial_timesteps   | 256            |\n",
      "| time_elapsed       | 260            |\n",
      "| total_timesteps    | 256            |\n",
      "| value_loss         | 4.1191943e-06  |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0013797992 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 29           |\n",
      "| n_updates          | 3            |\n",
      "| policy_entropy     | 1.4462066    |\n",
      "| policy_loss        | -0.005921551 |\n",
      "| serial_timesteps   | 384          |\n",
      "| time_elapsed       | 265          |\n",
      "| total_timesteps    | 384          |\n",
      "| value_loss         | 0.15003231   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00041052818 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 29            |\n",
      "| n_updates          | 4             |\n",
      "| policy_entropy     | 1.4978027     |\n",
      "| policy_loss        | -0.0031379946 |\n",
      "| serial_timesteps   | 512           |\n",
      "| time_elapsed       | 269           |\n",
      "| total_timesteps    | 512           |\n",
      "| value_loss         | 0.00015428757 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=516, episode_reward=1.20 +/- 2.04\n",
      "Episode length: 746.40 +/- 688.88\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005249817  |\n",
      "| clipfrac           | 0.01171875    |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 5             |\n",
      "| policy_entropy     | 1.519589      |\n",
      "| policy_loss        | -0.0067495466 |\n",
      "| serial_timesteps   | 640           |\n",
      "| time_elapsed       | 273           |\n",
      "| total_timesteps    | 640           |\n",
      "| value_loss         | 2.9929617e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.001507673   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 6             |\n",
      "| policy_entropy     | 1.5638654     |\n",
      "| policy_loss        | -0.0056278026 |\n",
      "| serial_timesteps   | 768           |\n",
      "| time_elapsed       | 391           |\n",
      "| total_timesteps    | 768           |\n",
      "| value_loss         | 0.16736077    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00046974886 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 7             |\n",
      "| policy_entropy     | 1.6176867     |\n",
      "| policy_loss        | -0.0008484322 |\n",
      "| serial_timesteps   | 896           |\n",
      "| time_elapsed       | 395           |\n",
      "| total_timesteps    | 896           |\n",
      "| value_loss         | 0.067577735   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=1016, episode_reward=0.80 +/- 1.83\n",
      "Episode length: 788.80 +/- 648.48\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00027289306 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 1.6133814     |\n",
      "| policy_loss        | -0.0029083008 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 399           |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 0.029630719   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004438024  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 29            |\n",
      "| n_updates          | 9             |\n",
      "| policy_entropy     | 1.615799      |\n",
      "| policy_loss        | -0.0024459157 |\n",
      "| serial_timesteps   | 1152          |\n",
      "| time_elapsed       | 520           |\n",
      "| total_timesteps    | 1152          |\n",
      "| value_loss         | 0.00044503852 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.751561e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 30             |\n",
      "| n_updates          | 10             |\n",
      "| policy_entropy     | 1.6055605      |\n",
      "| policy_loss        | -0.00026118057 |\n",
      "| serial_timesteps   | 1280           |\n",
      "| time_elapsed       | 524            |\n",
      "| total_timesteps    | 1280           |\n",
      "| value_loss         | 0.00018317714  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009983726  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 1.6057792     |\n",
      "| policy_loss        | -0.0042606737 |\n",
      "| serial_timesteps   | 1408          |\n",
      "| time_elapsed       | 528           |\n",
      "| total_timesteps    | 1408          |\n",
      "| value_loss         | 0.00013455041 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=1516, episode_reward=2.60 +/- 2.42\n",
      "Episode length: 1343.20 +/- 696.03\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00089884433 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 1.5558363     |\n",
      "| policy_loss        | -0.00262499   |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 532           |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 5.7484795e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00060446665 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.000861     |\n",
      "| fps                | 32            |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 1.5164323     |\n",
      "| policy_loss        | -0.0024439434 |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 734           |\n",
      "| total_timesteps    | 1664          |\n",
      "| value_loss         | 0.007999257   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000212554   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 32            |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 1.4908466     |\n",
      "| policy_loss        | 0.00063513557 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 738           |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 0.030008415   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.002045846  |\n",
      "| clipfrac           | 0.005859375  |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 31           |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 1.441273     |\n",
      "| policy_loss        | -0.014762558 |\n",
      "| serial_timesteps   | 1920         |\n",
      "| time_elapsed       | 742          |\n",
      "| total_timesteps    | 1920         |\n",
      "| value_loss         | 0.022540445  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=2016, episode_reward=1.60 +/- 1.02\n",
      "Episode length: 1437.60 +/- 693.69\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0019334775  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 1.3522921     |\n",
      "| policy_loss        | -0.0020955172 |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 746           |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 0.119844615   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007299177 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 29           |\n",
      "| n_updates          | 17           |\n",
      "| policy_entropy     | 1.329219     |\n",
      "| policy_loss        | -0.007721439 |\n",
      "| serial_timesteps   | 2176         |\n",
      "| time_elapsed       | 961          |\n",
      "| total_timesteps    | 2176         |\n",
      "| value_loss         | 0.0012654205 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015493114  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 1.3511572     |\n",
      "| policy_loss        | -0.0038851176 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 966           |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 3.397337e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0030677414  |\n",
      "| clipfrac           | 0.021484375   |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 1.4337333     |\n",
      "| policy_loss        | -0.011401131  |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 970           |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 3.6657252e-06 |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=2516, episode_reward=1.00 +/- 2.76\n",
      "Episode length: 864.00 +/- 927.76\n",
      "-------------------------------------\n",
      "| approxkl           | 0.004618162  |\n",
      "| clipfrac           | 0.00390625   |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 0            |\n",
      "| n_updates          | 20           |\n",
      "| policy_entropy     | 1.521817     |\n",
      "| policy_loss        | -0.010275351 |\n",
      "| serial_timesteps   | 2560         |\n",
      "| time_elapsed       | 974          |\n",
      "| total_timesteps    | 2560         |\n",
      "| value_loss         | 7.249707e-07 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010015075 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 31           |\n",
      "| n_updates          | 21           |\n",
      "| policy_entropy     | 1.5952145    |\n",
      "| policy_loss        | 0.0013286786 |\n",
      "| serial_timesteps   | 2688         |\n",
      "| time_elapsed       | 1.11e+03     |\n",
      "| total_timesteps    | 2688         |\n",
      "| value_loss         | 4.391979e-07 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00093787187 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 30            |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 1.621213      |\n",
      "| policy_loss        | -0.006055059  |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 1.11e+03      |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 4.0601668e-07 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010292971  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 29            |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 1.6474421     |\n",
      "| policy_loss        | -0.0051980466 |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 1.12e+03      |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 2.0832624e-07 |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import gym_gvgai\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import ActorCriticPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import SAC\n",
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import TRPO\n",
    "\n",
    "\n",
    "def show_state(env, step=0, name=\"\", info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name,step,info))\n",
    "    plt.axis('off')\n",
    "              \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl0-v0')\n",
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "log_path='./logs/', eval_freq=500,\n",
    "deterministic=True, render=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl0-v0')\n",
    "model = PPO2(MlpPolicy, env, verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"ppo2_zelda\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl1-v0')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"ppo2_zelda\")\n",
    "\n",
    "\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl2-v0')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"ppo2_zelda\")\n",
    "\n",
    "\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl3-v0')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"ppo2_zelda\")\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
