{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host 127.0.0.1 at port 55325 ...\n",
      "Client connected to server [OK]\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x10383fcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x10383fcd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x10383fcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x10383fcd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x13aa07f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x13aa07f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x13aa07f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x13aa07f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "-------------------------------------\n",
      "| approxkl           | 0.001437555  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0504      |\n",
      "| fps                | 22           |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 1.3846502    |\n",
      "| policy_loss        | -0.005294406 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 2.5e-05      |\n",
      "| total_timesteps    | 128          |\n",
      "| value_loss         | 0.32030576   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000175555   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 4.77e-07      |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 1.380805      |\n",
      "| policy_loss        | -0.0019257527 |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 5.8           |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 0.43095934    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039640267 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 1.3842211     |\n",
      "| policy_loss        | -0.0005032518 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 11            |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 0.5814649     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 466.80 +/- 250.53\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012017107 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 4             |\n",
      "| policy_entropy     | 1.3843212     |\n",
      "| policy_loss        | -0.0017766906 |\n",
      "| serial_timesteps   | 512           |\n",
      "| time_elapsed       | 16.2          |\n",
      "| total_timesteps    | 512           |\n",
      "| value_loss         | 0.29562497    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001968968  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 5             |\n",
      "| policy_entropy     | 1.383879      |\n",
      "| policy_loss        | 0.00038917945 |\n",
      "| serial_timesteps   | 640           |\n",
      "| time_elapsed       | 96.8          |\n",
      "| total_timesteps    | 640           |\n",
      "| value_loss         | 0.26174363    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 1.734479e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 6            |\n",
      "| policy_entropy     | 1.382817     |\n",
      "| policy_loss        | 0.0001301557 |\n",
      "| serial_timesteps   | 768          |\n",
      "| time_elapsed       | 102          |\n",
      "| total_timesteps    | 768          |\n",
      "| value_loss         | 1.9550261    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0001844489 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 7            |\n",
      "| policy_entropy     | 1.3831435    |\n",
      "| policy_loss        | -0.001994244 |\n",
      "| serial_timesteps   | 896          |\n",
      "| time_elapsed       | 107          |\n",
      "| total_timesteps    | 896          |\n",
      "| value_loss         | 0.75920516   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 443.20 +/- 161.67\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0005817887 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 1            |\n",
      "| n_updates          | 8            |\n",
      "| policy_entropy     | 1.383675     |\n",
      "| policy_loss        | -0.001940242 |\n",
      "| serial_timesteps   | 1024         |\n",
      "| time_elapsed       | 112          |\n",
      "| total_timesteps    | 1024         |\n",
      "| value_loss         | 0.1520935    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.000539612  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 1.3811004    |\n",
      "| policy_loss        | -0.003969362 |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 189          |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 0.39880663   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0012040437  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 1.3769307     |\n",
      "| policy_loss        | 0.00025649578 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 194           |\n",
      "| total_timesteps    | 1280          |\n",
      "| value_loss         | 1.3803844     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017454762 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 1.3733646     |\n",
      "| policy_loss        | -0.0009988645 |\n",
      "| serial_timesteps   | 1408          |\n",
      "| time_elapsed       | 199           |\n",
      "| total_timesteps    | 1408          |\n",
      "| value_loss         | 0.32957295    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=1500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 495.40 +/- 161.26\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004186165  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 1.365425      |\n",
      "| policy_loss        | -0.0020246934 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 204           |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 0.80360794    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00028885916 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 1.3615997     |\n",
      "| policy_loss        | -0.003953713  |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 288           |\n",
      "| total_timesteps    | 1664          |\n",
      "| value_loss         | 0.62071675    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011735248  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 1.3730651     |\n",
      "| policy_loss        | -0.0026659584 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 293           |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 0.596433      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020902968 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 15            |\n",
      "| policy_entropy     | 1.3777806     |\n",
      "| policy_loss        | 0.00016866229 |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 298           |\n",
      "| total_timesteps    | 1920          |\n",
      "| value_loss         | 1.2121257     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 4.16882e-05   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 1.3792973     |\n",
      "| policy_loss        | 0.00020630483 |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 304           |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 0.31287965    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.7907644e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 1.3802621     |\n",
      "| policy_loss        | -6.813032e-05 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 363           |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 0.57820475    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00026260657 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 1.3820062     |\n",
      "| policy_loss        | -0.0021747109 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 368           |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 1.592533      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00031954277 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 1.3815216     |\n",
      "| policy_loss        | -0.0029043425 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 373           |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 0.25147247    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=2500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 670.20 +/- 157.64\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00027428   |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 1            |\n",
      "| n_updates          | 20           |\n",
      "| policy_entropy     | 1.3785272    |\n",
      "| policy_loss        | 0.0015071608 |\n",
      "| serial_timesteps   | 2560         |\n",
      "| time_elapsed       | 379          |\n",
      "| total_timesteps    | 2560         |\n",
      "| value_loss         | 0.56333494   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0001227598   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 1.19e-07       |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 21             |\n",
      "| policy_entropy     | 1.3765206      |\n",
      "| policy_loss        | -0.00067314354 |\n",
      "| serial_timesteps   | 2688           |\n",
      "| time_elapsed       | 490            |\n",
      "| total_timesteps    | 2688           |\n",
      "| value_loss         | 0.8856616      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002796619  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 1.3737824     |\n",
      "| policy_loss        | -0.0017209719 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 495           |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 1.5648923     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007418117 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 23           |\n",
      "| policy_entropy     | 1.3741891    |\n",
      "| policy_loss        | -0.00469991  |\n",
      "| serial_timesteps   | 2944         |\n",
      "| time_elapsed       | 500          |\n",
      "| total_timesteps    | 2944         |\n",
      "| value_loss         | 0.5027434    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 543.40 +/- 198.75\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00044019072  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 1              |\n",
      "| n_updates          | 24             |\n",
      "| policy_entropy     | 1.3745203      |\n",
      "| policy_loss        | -3.1306176e-05 |\n",
      "| serial_timesteps   | 3072           |\n",
      "| time_elapsed       | 505            |\n",
      "| total_timesteps    | 3072           |\n",
      "| value_loss         | 1.1332163      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00028019815 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 1.3711948     |\n",
      "| policy_loss        | -0.0017670606 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 599           |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 1.1629462     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00021686633  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.19e-07      |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 26             |\n",
      "| policy_entropy     | 1.366997       |\n",
      "| policy_loss        | -0.00063494046 |\n",
      "| serial_timesteps   | 3328           |\n",
      "| time_elapsed       | 604            |\n",
      "| total_timesteps    | 3328           |\n",
      "| value_loss         | 0.4478586      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00042751123 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 1.3572108     |\n",
      "| policy_loss        | -0.0028935259 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 610           |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 0.84793365    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=3500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 339.80 +/- 234.64\n",
      "-------------------------------------\n",
      "| approxkl           | 0.000648428  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 2            |\n",
      "| n_updates          | 28           |\n",
      "| policy_entropy     | 1.3418462    |\n",
      "| policy_loss        | 0.0012966914 |\n",
      "| serial_timesteps   | 3584         |\n",
      "| time_elapsed       | 615          |\n",
      "| total_timesteps    | 3584         |\n",
      "| value_loss         | 0.599578     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.4865596e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 5.96e-08       |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 29             |\n",
      "| policy_entropy     | 1.338986       |\n",
      "| policy_loss        | -0.00013122917 |\n",
      "| serial_timesteps   | 3712           |\n",
      "| time_elapsed       | 675            |\n",
      "| total_timesteps    | 3712           |\n",
      "| value_loss         | 0.37193686     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.398815e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 30            |\n",
      "| policy_entropy     | 1.3407016     |\n",
      "| policy_loss        | 0.00040446664 |\n",
      "| serial_timesteps   | 3840          |\n",
      "| time_elapsed       | 681           |\n",
      "| total_timesteps    | 3840          |\n",
      "| value_loss         | 1.4999756     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00021338741  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 31             |\n",
      "| policy_entropy     | 1.3474402      |\n",
      "| policy_loss        | -0.00083066593 |\n",
      "| serial_timesteps   | 3968           |\n",
      "| time_elapsed       | 686            |\n",
      "| total_timesteps    | 3968           |\n",
      "| value_loss         | 0.88448536     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 634.40 +/- 189.03\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00015574398  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 1              |\n",
      "| n_updates          | 32             |\n",
      "| policy_entropy     | 1.3556672      |\n",
      "| policy_loss        | -0.00060136616 |\n",
      "| serial_timesteps   | 4096           |\n",
      "| time_elapsed       | 691            |\n",
      "| total_timesteps    | 4096           |\n",
      "| value_loss         | 0.18029574     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.0945557e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 1.35535       |\n",
      "| policy_loss        | -6.153493e-05 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 800           |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 0.7881151     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019403039 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 1.3552837     |\n",
      "| policy_loss        | -0.0017992062 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 805           |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 0.3006939     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007371202 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 35           |\n",
      "| policy_entropy     | 1.3384768    |\n",
      "| policy_loss        | -0.001268391 |\n",
      "| serial_timesteps   | 4480         |\n",
      "| time_elapsed       | 810          |\n",
      "| total_timesteps    | 4480         |\n",
      "| value_loss         | 0.26257718   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=4500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 584.00 +/- 156.60\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002479903 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 1.19e-07     |\n",
      "| fps                | 1            |\n",
      "| n_updates          | 36           |\n",
      "| policy_entropy     | 1.3339933    |\n",
      "| policy_loss        | -0.00242295  |\n",
      "| serial_timesteps   | 4608         |\n",
      "| time_elapsed       | 815          |\n",
      "| total_timesteps    | 4608         |\n",
      "| value_loss         | 0.22645158   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009471257  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 37            |\n",
      "| policy_entropy     | 1.3450005     |\n",
      "| policy_loss        | -0.0004842881 |\n",
      "| serial_timesteps   | 4736          |\n",
      "| time_elapsed       | 913           |\n",
      "| total_timesteps    | 4736          |\n",
      "| value_loss         | 0.93453664    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.6934358e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 1.3441696     |\n",
      "| policy_loss        | 9.922648e-05  |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 918           |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 0.71339375    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013756254 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 1.3504705     |\n",
      "| policy_loss        | 0.00021599839 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 923           |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 0.90205353    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 411.80 +/- 247.70\n",
      "--------------------------------------\n",
      "| approxkl           | 8.0309765e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 1.3561857     |\n",
      "| policy_loss        | 0.0004658791  |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 928           |\n",
      "| total_timesteps    | 5120          |\n",
      "| value_loss         | 0.1776961     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 6.747463e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 1.3572868     |\n",
      "| policy_loss        | -0.0014222916 |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 999           |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 0.9023753     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0008243908 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 42           |\n",
      "| policy_entropy     | 1.3598757    |\n",
      "| policy_loss        | -0.005605687 |\n",
      "| serial_timesteps   | 5376         |\n",
      "| time_elapsed       | 1e+03        |\n",
      "| total_timesteps    | 5376         |\n",
      "| value_loss         | 0.4035318    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=5500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 550.60 +/- 147.37\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0008528723 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 1            |\n",
      "| n_updates          | 43           |\n",
      "| policy_entropy     | 1.362952     |\n",
      "| policy_loss        | -0.005165855 |\n",
      "| serial_timesteps   | 5504         |\n",
      "| time_elapsed       | 1.01e+03     |\n",
      "| total_timesteps    | 5504         |\n",
      "| value_loss         | 0.17062554   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0027239176 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 44           |\n",
      "| policy_entropy     | 1.347337     |\n",
      "| policy_loss        | -0.006045607 |\n",
      "| serial_timesteps   | 5632         |\n",
      "| time_elapsed       | 1.1e+03      |\n",
      "| total_timesteps    | 5632         |\n",
      "| value_loss         | 0.28863403   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00054465514 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 45            |\n",
      "| policy_entropy     | 1.328204      |\n",
      "| policy_loss        | -0.0021273964 |\n",
      "| serial_timesteps   | 5760          |\n",
      "| time_elapsed       | 1.11e+03      |\n",
      "| total_timesteps    | 5760          |\n",
      "| value_loss         | 0.3842378     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00070414785 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 46            |\n",
      "| policy_entropy     | 1.3172607     |\n",
      "| policy_loss        | -0.0039942437 |\n",
      "| serial_timesteps   | 5888          |\n",
      "| time_elapsed       | 1.11e+03      |\n",
      "| total_timesteps    | 5888          |\n",
      "| value_loss         | 0.44237456    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00058422313  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.19e-07      |\n",
      "| fps                | 2              |\n",
      "| n_updates          | 47             |\n",
      "| policy_entropy     | 1.3172623      |\n",
      "| policy_loss        | -9.7423675e-05 |\n",
      "| serial_timesteps   | 6016           |\n",
      "| time_elapsed       | 1.12e+03       |\n",
      "| total_timesteps    | 6016           |\n",
      "| value_loss         | 0.24123323     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011423989  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 26            |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 1.3096688     |\n",
      "| policy_loss        | -0.0054789707 |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 1.17e+03      |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 0.43284917    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.001107507   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 1.2808689     |\n",
      "| policy_loss        | -0.0019284107 |\n",
      "| serial_timesteps   | 6272          |\n",
      "| time_elapsed       | 1.18e+03      |\n",
      "| total_timesteps    | 6272          |\n",
      "| value_loss         | 1.080983      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001774185  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 27            |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 1.267763      |\n",
      "| policy_loss        | -0.0001697184 |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 1.18e+03      |\n",
      "| total_timesteps    | 6400          |\n",
      "| value_loss         | 0.63982034    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=6500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006143946  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 1.288011      |\n",
      "| policy_loss        | -0.0011525734 |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 1.19e+03      |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 0.25051057    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 7.153233e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 52           |\n",
      "| policy_entropy     | 1.3018668    |\n",
      "| policy_loss        | 0.0009622737 |\n",
      "| serial_timesteps   | 6656         |\n",
      "| time_elapsed       | 1.25e+03     |\n",
      "| total_timesteps    | 6656         |\n",
      "| value_loss         | 0.5860753    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8368922e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 53             |\n",
      "| policy_entropy     | 1.3028075      |\n",
      "| policy_loss        | -5.7024765e-05 |\n",
      "| serial_timesteps   | 6784           |\n",
      "| time_elapsed       | 1.25e+03       |\n",
      "| total_timesteps    | 6784           |\n",
      "| value_loss         | 1.0353123      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00104215   |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 54           |\n",
      "| policy_entropy     | 1.2918779    |\n",
      "| policy_loss        | -0.004552354 |\n",
      "| serial_timesteps   | 6912         |\n",
      "| time_elapsed       | 1.26e+03     |\n",
      "| total_timesteps    | 6912         |\n",
      "| value_loss         | 0.6423316    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007510014  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 55            |\n",
      "| policy_entropy     | 1.260363      |\n",
      "| policy_loss        | 0.00014907634 |\n",
      "| serial_timesteps   | 7040          |\n",
      "| time_elapsed       | 1.26e+03      |\n",
      "| total_timesteps    | 7040          |\n",
      "| value_loss         | 0.29713374    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.001154848  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 56           |\n",
      "| policy_entropy     | 1.2281301    |\n",
      "| policy_loss        | -0.005022455 |\n",
      "| serial_timesteps   | 7168         |\n",
      "| time_elapsed       | 1.32e+03     |\n",
      "| total_timesteps    | 7168         |\n",
      "| value_loss         | 0.38336033   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0012253271  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 57            |\n",
      "| policy_entropy     | 1.1718408     |\n",
      "| policy_loss        | 0.00036668568 |\n",
      "| serial_timesteps   | 7296          |\n",
      "| time_elapsed       | 1.33e+03      |\n",
      "| total_timesteps    | 7296          |\n",
      "| value_loss         | 0.7677011     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.588217e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 58             |\n",
      "| policy_entropy     | 1.1578481      |\n",
      "| policy_loss        | -1.0369811e-05 |\n",
      "| serial_timesteps   | 7424           |\n",
      "| time_elapsed       | 1.33e+03       |\n",
      "| total_timesteps    | 7424           |\n",
      "| value_loss         | 1.459306       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=7500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004409333  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 1.1539484     |\n",
      "| policy_loss        | -0.0032667737 |\n",
      "| serial_timesteps   | 7552          |\n",
      "| time_elapsed       | 1.34e+03      |\n",
      "| total_timesteps    | 7552          |\n",
      "| value_loss         | 0.38618568    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0005201688   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 60             |\n",
      "| policy_entropy     | 1.1390482      |\n",
      "| policy_loss        | -2.4130335e-05 |\n",
      "| serial_timesteps   | 7680           |\n",
      "| time_elapsed       | 1.4e+03        |\n",
      "| total_timesteps    | 7680           |\n",
      "| value_loss         | 0.74179643     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000541531    |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 61             |\n",
      "| policy_entropy     | 1.1587822      |\n",
      "| policy_loss        | -0.00069141714 |\n",
      "| serial_timesteps   | 7808           |\n",
      "| time_elapsed       | 1.4e+03        |\n",
      "| total_timesteps    | 7808           |\n",
      "| value_loss         | 1.2951535      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009501913  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 62            |\n",
      "| policy_entropy     | 1.1784904     |\n",
      "| policy_loss        | -0.0049384334 |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 1.41e+03      |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 0.20500125    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016189883  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 63            |\n",
      "| policy_entropy     | 1.225644      |\n",
      "| policy_loss        | -0.0033940012 |\n",
      "| serial_timesteps   | 8064          |\n",
      "| time_elapsed       | 1.41e+03      |\n",
      "| total_timesteps    | 8064          |\n",
      "| value_loss         | 0.21430661    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011187762  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 1.2516687     |\n",
      "| policy_loss        | -0.0046012974 |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 1.47e+03      |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 0.5173811     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0018609898  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 65            |\n",
      "| policy_entropy     | 1.2496994     |\n",
      "| policy_loss        | -0.0052859075 |\n",
      "| serial_timesteps   | 8320          |\n",
      "| time_elapsed       | 1.48e+03      |\n",
      "| total_timesteps    | 8320          |\n",
      "| value_loss         | 0.54215133    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037276986 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 1.2594694     |\n",
      "| policy_loss        | 0.000731954   |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 1.48e+03      |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 1.6227505     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=8500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 591.40 +/- 154.07\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00053829176 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 67            |\n",
      "| policy_entropy     | 1.2782927     |\n",
      "| policy_loss        | -0.003125053  |\n",
      "| serial_timesteps   | 8576          |\n",
      "| time_elapsed       | 1.49e+03      |\n",
      "| total_timesteps    | 8576          |\n",
      "| value_loss         | 0.7877161     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00063498196 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 68            |\n",
      "| policy_entropy     | 1.2999687     |\n",
      "| policy_loss        | 0.00062254735 |\n",
      "| serial_timesteps   | 8704          |\n",
      "| time_elapsed       | 1.59e+03      |\n",
      "| total_timesteps    | 8704          |\n",
      "| value_loss         | 1.354673      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.35509e-05   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 69            |\n",
      "| policy_entropy     | 1.3083305     |\n",
      "| policy_loss        | -0.0008329863 |\n",
      "| serial_timesteps   | 8832          |\n",
      "| time_elapsed       | 1.59e+03      |\n",
      "| total_timesteps    | 8832          |\n",
      "| value_loss         | 1.209936      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 8.530475e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 70           |\n",
      "| policy_entropy     | 1.3074946    |\n",
      "| policy_loss        | 0.0010885097 |\n",
      "| serial_timesteps   | 8960         |\n",
      "| time_elapsed       | 1.6e+03      |\n",
      "| total_timesteps    | 8960         |\n",
      "| value_loss         | 0.25334865   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 342.20 +/- 231.36\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002017126 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 2            |\n",
      "| n_updates          | 71           |\n",
      "| policy_entropy     | 1.3007402    |\n",
      "| policy_loss        | 0.0001230617 |\n",
      "| serial_timesteps   | 9088         |\n",
      "| time_elapsed       | 1.6e+03      |\n",
      "| total_timesteps    | 9088         |\n",
      "| value_loss         | 0.28666934   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00029386437 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 72            |\n",
      "| policy_entropy     | 1.2868062     |\n",
      "| policy_loss        | -0.0013883167 |\n",
      "| serial_timesteps   | 9216          |\n",
      "| time_elapsed       | 1.66e+03      |\n",
      "| total_timesteps    | 9216          |\n",
      "| value_loss         | 1.1358893     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 0.00015454163  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 73             |\n",
      "| policy_entropy     | 1.273875       |\n",
      "| policy_loss        | -0.00013708975 |\n",
      "| serial_timesteps   | 9344           |\n",
      "| time_elapsed       | 1.67e+03       |\n",
      "| total_timesteps    | 9344           |\n",
      "| value_loss         | 0.82215524     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023389123 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 74            |\n",
      "| policy_entropy     | 1.2667712     |\n",
      "| policy_loss        | -0.0022505359 |\n",
      "| serial_timesteps   | 9472          |\n",
      "| time_elapsed       | 1.67e+03      |\n",
      "| total_timesteps    | 9472          |\n",
      "| value_loss         | 0.26782805    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=9500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 564.80 +/- 259.68\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00040451577 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 1.2487342     |\n",
      "| policy_loss        | -0.0016114397 |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 1.68e+03      |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 0.27316338    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00026216483  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 76             |\n",
      "| policy_entropy     | 1.2273035      |\n",
      "| policy_loss        | -0.00020841334 |\n",
      "| serial_timesteps   | 9728           |\n",
      "| time_elapsed       | 1.77e+03       |\n",
      "| total_timesteps    | 9728           |\n",
      "| value_loss         | 0.7747083      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00024287851 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 1.2200339     |\n",
      "| policy_loss        | -0.0029145277 |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 1.78e+03      |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 1.5540782     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0013126197  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.79e-07      |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 1.1980944     |\n",
      "| policy_loss        | -0.0050065056 |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 1.78e+03      |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 0.34043193    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 8.1760576e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 79            |\n",
      "| policy_entropy     | 1.1781154     |\n",
      "| policy_loss        | 0.000492568   |\n",
      "| serial_timesteps   | 10112         |\n",
      "| time_elapsed       | 1.79e+03      |\n",
      "| total_timesteps    | 10112         |\n",
      "| value_loss         | 0.26328924    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006248746  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 80            |\n",
      "| policy_entropy     | 1.1888801     |\n",
      "| policy_loss        | -0.0010008758 |\n",
      "| serial_timesteps   | 10240         |\n",
      "| time_elapsed       | 1.85e+03      |\n",
      "| total_timesteps    | 10240         |\n",
      "| value_loss         | 0.9171761     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00021880814 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 81            |\n",
      "| policy_entropy     | 1.1956072     |\n",
      "| policy_loss        | -0.0014795256 |\n",
      "| serial_timesteps   | 10368         |\n",
      "| time_elapsed       | 1.85e+03      |\n",
      "| total_timesteps    | 10368         |\n",
      "| value_loss         | 1.2031035     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00033956312 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 82            |\n",
      "| policy_entropy     | 1.2084521     |\n",
      "| policy_loss        | -0.0021508697 |\n",
      "| serial_timesteps   | 10496         |\n",
      "| time_elapsed       | 1.86e+03      |\n",
      "| total_timesteps    | 10496         |\n",
      "| value_loss         | 0.4507579     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=10500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 459.40 +/- 240.51\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015504245 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 83            |\n",
      "| policy_entropy     | 1.230618      |\n",
      "| policy_loss        | 0.0005674581  |\n",
      "| serial_timesteps   | 10624         |\n",
      "| time_elapsed       | 1.86e+03      |\n",
      "| total_timesteps    | 10624         |\n",
      "| value_loss         | 0.34676722    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0013086981  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 84            |\n",
      "| policy_entropy     | 1.2085463     |\n",
      "| policy_loss        | -0.0058089346 |\n",
      "| serial_timesteps   | 10752         |\n",
      "| time_elapsed       | 1.94e+03      |\n",
      "| total_timesteps    | 10752         |\n",
      "| value_loss         | 0.59502757    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009010198  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 85            |\n",
      "| policy_entropy     | 1.1619841     |\n",
      "| policy_loss        | 0.00020529318 |\n",
      "| serial_timesteps   | 10880         |\n",
      "| time_elapsed       | 1.94e+03      |\n",
      "| total_timesteps    | 10880         |\n",
      "| value_loss         | 1.9010414     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008554979  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 86            |\n",
      "| policy_entropy     | 1.1501366     |\n",
      "| policy_loss        | -0.0036422864 |\n",
      "| serial_timesteps   | 11008         |\n",
      "| time_elapsed       | 1.95e+03      |\n",
      "| total_timesteps    | 11008         |\n",
      "| value_loss         | 0.7875898     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0003469429 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 87           |\n",
      "| policy_entropy     | 1.151354     |\n",
      "| policy_loss        | -0.001543297 |\n",
      "| serial_timesteps   | 11136        |\n",
      "| time_elapsed       | 2.01e+03     |\n",
      "| total_timesteps    | 11136        |\n",
      "| value_loss         | 0.6243378    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00058035145  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 88             |\n",
      "| policy_entropy     | 1.1716228      |\n",
      "| policy_loss        | -0.00090081536 |\n",
      "| serial_timesteps   | 11264          |\n",
      "| time_elapsed       | 2.01e+03       |\n",
      "| total_timesteps    | 11264          |\n",
      "| value_loss         | 1.0443277      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.000302249   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 89            |\n",
      "| policy_entropy     | 1.1798997     |\n",
      "| policy_loss        | -0.0021745681 |\n",
      "| serial_timesteps   | 11392         |\n",
      "| time_elapsed       | 2.02e+03      |\n",
      "| total_timesteps    | 11392         |\n",
      "| value_loss         | 0.22490288    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=11500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012618727 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 90            |\n",
      "| policy_entropy     | 1.188165      |\n",
      "| policy_loss        | 0.000838898   |\n",
      "| serial_timesteps   | 11520         |\n",
      "| time_elapsed       | 2.02e+03      |\n",
      "| total_timesteps    | 11520         |\n",
      "| value_loss         | 0.3585403     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00021865763 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 91            |\n",
      "| policy_entropy     | 1.1766386     |\n",
      "| policy_loss        | -0.000532045  |\n",
      "| serial_timesteps   | 11648         |\n",
      "| time_elapsed       | 2.08e+03      |\n",
      "| total_timesteps    | 11648         |\n",
      "| value_loss         | 1.6275599     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014981197 |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 92           |\n",
      "| policy_entropy     | 1.1839756    |\n",
      "| policy_loss        | -0.007044073 |\n",
      "| serial_timesteps   | 11776        |\n",
      "| time_elapsed       | 2.09e+03     |\n",
      "| total_timesteps    | 11776        |\n",
      "| value_loss         | 0.35624182   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005009867  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 93            |\n",
      "| policy_entropy     | 1.2130382     |\n",
      "| policy_loss        | -0.0015119864 |\n",
      "| serial_timesteps   | 11904         |\n",
      "| time_elapsed       | 2.09e+03      |\n",
      "| total_timesteps    | 11904         |\n",
      "| value_loss         | 1.947527      |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0021407406 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -2.38e-07    |\n",
      "| fps                | 2            |\n",
      "| n_updates          | 94           |\n",
      "| policy_entropy     | 1.2200506    |\n",
      "| policy_loss        | -0.006704678 |\n",
      "| serial_timesteps   | 12032        |\n",
      "| time_elapsed       | 2.1e+03      |\n",
      "| total_timesteps    | 12032        |\n",
      "| value_loss         | 0.3327662    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0018982467  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 95            |\n",
      "| policy_entropy     | 1.2089832     |\n",
      "| policy_loss        | -0.0017936002 |\n",
      "| serial_timesteps   | 12160         |\n",
      "| time_elapsed       | 2.16e+03      |\n",
      "| total_timesteps    | 12160         |\n",
      "| value_loss         | 0.24407212    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004633721  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.36e-07      |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 96            |\n",
      "| policy_entropy     | 1.194832      |\n",
      "| policy_loss        | -0.0007745966 |\n",
      "| serial_timesteps   | 12288         |\n",
      "| time_elapsed       | 2.16e+03      |\n",
      "| total_timesteps    | 12288         |\n",
      "| value_loss         | 0.51864445    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00017076031  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 97             |\n",
      "| policy_entropy     | 1.1747859      |\n",
      "| policy_loss        | -0.00019122148 |\n",
      "| serial_timesteps   | 12416          |\n",
      "| time_elapsed       | 2.17e+03       |\n",
      "| total_timesteps    | 12416          |\n",
      "| value_loss         | 0.4622491      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=12500, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 674.80 +/- 196.40\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00040603237 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 98            |\n",
      "| policy_entropy     | 1.1659228     |\n",
      "| policy_loss        | -0.004652544  |\n",
      "| serial_timesteps   | 12544         |\n",
      "| time_elapsed       | 2.17e+03      |\n",
      "| total_timesteps    | 12544         |\n",
      "| value_loss         | 0.2381789     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006459739 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 99           |\n",
      "| policy_entropy     | 1.1886221    |\n",
      "| policy_loss        | 0.0024325335 |\n",
      "| serial_timesteps   | 12672        |\n",
      "| time_elapsed       | 2.29e+03     |\n",
      "| total_timesteps    | 12672        |\n",
      "| value_loss         | 0.38271973   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00045117317 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 100           |\n",
      "| policy_entropy     | 1.1936136     |\n",
      "| policy_loss        | -0.0026393915 |\n",
      "| serial_timesteps   | 12800         |\n",
      "| time_elapsed       | 2.29e+03      |\n",
      "| total_timesteps    | 12800         |\n",
      "| value_loss         | 0.27043718    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00049355725 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 101           |\n",
      "| policy_entropy     | 1.1859883     |\n",
      "| policy_loss        | 0.0010761055  |\n",
      "| serial_timesteps   | 12928         |\n",
      "| time_elapsed       | 2.3e+03       |\n",
      "| total_timesteps    | 12928         |\n",
      "| value_loss         | 0.84391516    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 483.80 +/- 166.55\n",
      "---------------------------------------\n",
      "| approxkl           | 6.695565e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 1              |\n",
      "| n_updates          | 102            |\n",
      "| policy_entropy     | 1.1868473      |\n",
      "| policy_loss        | -0.00042265432 |\n",
      "| serial_timesteps   | 13056          |\n",
      "| time_elapsed       | 2.3e+03        |\n",
      "| total_timesteps    | 13056          |\n",
      "| value_loss         | 1.5344294      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0035300977 |\n",
      "| clipfrac           | 0.015625     |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 103          |\n",
      "| policy_entropy     | 1.2133713    |\n",
      "| policy_loss        | -0.008514823 |\n",
      "| serial_timesteps   | 13184        |\n",
      "| time_elapsed       | 2.38e+03     |\n",
      "| total_timesteps    | 13184        |\n",
      "| value_loss         | 0.2972349    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011882378  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 104           |\n",
      "| policy_entropy     | 1.2203645     |\n",
      "| policy_loss        | -0.0021202625 |\n",
      "| serial_timesteps   | 13312         |\n",
      "| time_elapsed       | 2.39e+03      |\n",
      "| total_timesteps    | 13312         |\n",
      "| value_loss         | 1.6668202     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0012124033 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 1.19e-07     |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 105          |\n",
      "| policy_entropy     | 1.2195837    |\n",
      "| policy_loss        | -0.007933179 |\n",
      "| serial_timesteps   | 13440        |\n",
      "| time_elapsed       | 2.39e+03     |\n",
      "| total_timesteps    | 13440        |\n",
      "| value_loss         | 0.52748847   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=13500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002079732   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 106           |\n",
      "| policy_entropy     | 1.1900678     |\n",
      "| policy_loss        | -0.0047983117 |\n",
      "| serial_timesteps   | 13568         |\n",
      "| time_elapsed       | 2.4e+03       |\n",
      "| total_timesteps    | 13568         |\n",
      "| value_loss         | 1.1592859     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00051800325 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 107           |\n",
      "| policy_entropy     | 1.1787126     |\n",
      "| policy_loss        | -0.0043474585 |\n",
      "| serial_timesteps   | 13696         |\n",
      "| time_elapsed       | 2.46e+03      |\n",
      "| total_timesteps    | 13696         |\n",
      "| value_loss         | 0.1831265     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0020721308  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 108           |\n",
      "| policy_entropy     | 1.2123185     |\n",
      "| policy_loss        | -0.0018401078 |\n",
      "| serial_timesteps   | 13824         |\n",
      "| time_elapsed       | 2.46e+03      |\n",
      "| total_timesteps    | 13824         |\n",
      "| value_loss         | 0.7985544     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002118134  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 109           |\n",
      "| policy_entropy     | 1.2225353     |\n",
      "| policy_loss        | -0.0011664883 |\n",
      "| serial_timesteps   | 13952         |\n",
      "| time_elapsed       | 2.47e+03      |\n",
      "| total_timesteps    | 13952         |\n",
      "| value_loss         | 0.88910025    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009148776  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 110           |\n",
      "| policy_entropy     | 1.2150595     |\n",
      "| policy_loss        | -0.0054984335 |\n",
      "| serial_timesteps   | 14080         |\n",
      "| time_elapsed       | 2.47e+03      |\n",
      "| total_timesteps    | 14080         |\n",
      "| value_loss         | 0.45976466    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.8243405e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 111           |\n",
      "| policy_entropy     | 1.214149      |\n",
      "| policy_loss        | 0.00062709046 |\n",
      "| serial_timesteps   | 14208         |\n",
      "| time_elapsed       | 2.53e+03      |\n",
      "| total_timesteps    | 14208         |\n",
      "| value_loss         | 0.50109357    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.0593454e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 112           |\n",
      "| policy_entropy     | 1.2142079     |\n",
      "| policy_loss        | 0.00059105584 |\n",
      "| serial_timesteps   | 14336         |\n",
      "| time_elapsed       | 2.54e+03      |\n",
      "| total_timesteps    | 14336         |\n",
      "| value_loss         | 1.5027897     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010178353 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 113          |\n",
      "| policy_entropy     | 1.1966513    |\n",
      "| policy_loss        | -0.004668652 |\n",
      "| serial_timesteps   | 14464        |\n",
      "| time_elapsed       | 2.54e+03     |\n",
      "| total_timesteps    | 14464        |\n",
      "| value_loss         | 0.32587942   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=14500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0006843348   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 5.96e-08       |\n",
      "| fps                | 2              |\n",
      "| n_updates          | 114            |\n",
      "| policy_entropy     | 1.1687527      |\n",
      "| policy_loss        | -7.2829425e-06 |\n",
      "| serial_timesteps   | 14592          |\n",
      "| time_elapsed       | 2.55e+03       |\n",
      "| total_timesteps    | 14592          |\n",
      "| value_loss         | 0.37591743     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004968849  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 115           |\n",
      "| policy_entropy     | 1.179205      |\n",
      "| policy_loss        | -0.0039854916 |\n",
      "| serial_timesteps   | 14720         |\n",
      "| time_elapsed       | 2.61e+03      |\n",
      "| total_timesteps    | 14720         |\n",
      "| value_loss         | 0.8898693     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009370759  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 116           |\n",
      "| policy_entropy     | 1.2095649     |\n",
      "| policy_loss        | -0.0046959366 |\n",
      "| serial_timesteps   | 14848         |\n",
      "| time_elapsed       | 2.61e+03      |\n",
      "| total_timesteps    | 14848         |\n",
      "| value_loss         | 2.2888927     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000273131    |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 117            |\n",
      "| policy_entropy     | 1.2280786      |\n",
      "| policy_loss        | -0.00030054967 |\n",
      "| serial_timesteps   | 14976          |\n",
      "| time_elapsed       | 2.62e+03       |\n",
      "| total_timesteps    | 14976          |\n",
      "| value_loss         | 0.5122014      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0009463004  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 118           |\n",
      "| policy_entropy     | 1.2337184     |\n",
      "| policy_loss        | -0.0047199926 |\n",
      "| serial_timesteps   | 15104         |\n",
      "| time_elapsed       | 2.62e+03      |\n",
      "| total_timesteps    | 15104         |\n",
      "| value_loss         | 0.7558908     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0020788843  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 119           |\n",
      "| policy_entropy     | 1.2051251     |\n",
      "| policy_loss        | -0.0076313433 |\n",
      "| serial_timesteps   | 15232         |\n",
      "| time_elapsed       | 2.68e+03      |\n",
      "| total_timesteps    | 15232         |\n",
      "| value_loss         | 0.87976706    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00052964996 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 120           |\n",
      "| policy_entropy     | 1.1769956     |\n",
      "| policy_loss        | 0.00095490133 |\n",
      "| serial_timesteps   | 15360         |\n",
      "| time_elapsed       | 2.69e+03      |\n",
      "| total_timesteps    | 15360         |\n",
      "| value_loss         | 0.4766238     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 0.00023836322  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 121            |\n",
      "| policy_entropy     | 1.1809996      |\n",
      "| policy_loss        | -0.00037049945 |\n",
      "| serial_timesteps   | 15488          |\n",
      "| time_elapsed       | 2.7e+03        |\n",
      "| total_timesteps    | 15488          |\n",
      "| value_loss         | 0.332745       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=15500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0008748096 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 1.19e-07     |\n",
      "| fps                | 2            |\n",
      "| n_updates          | 122          |\n",
      "| policy_entropy     | 1.1587176    |\n",
      "| policy_loss        | -0.003402795 |\n",
      "| serial_timesteps   | 15616        |\n",
      "| time_elapsed       | 2.7e+03      |\n",
      "| total_timesteps    | 15616        |\n",
      "| value_loss         | 0.3143418    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006636535  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 123           |\n",
      "| policy_entropy     | 1.1134721     |\n",
      "| policy_loss        | -0.0015073991 |\n",
      "| serial_timesteps   | 15744         |\n",
      "| time_elapsed       | 2.76e+03      |\n",
      "| total_timesteps    | 15744         |\n",
      "| value_loss         | 1.326397      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018040651 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 124           |\n",
      "| policy_entropy     | 1.0889045     |\n",
      "| policy_loss        | -0.0005955439 |\n",
      "| serial_timesteps   | 15872         |\n",
      "| time_elapsed       | 2.76e+03      |\n",
      "| total_timesteps    | 15872         |\n",
      "| value_loss         | 0.5300429     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037663212 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 125           |\n",
      "| policy_entropy     | 1.066514      |\n",
      "| policy_loss        | -0.0020461641 |\n",
      "| serial_timesteps   | 16000         |\n",
      "| time_elapsed       | 2.77e+03      |\n",
      "| total_timesteps    | 16000         |\n",
      "| value_loss         | 0.5102885     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00081587676 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 126           |\n",
      "| policy_entropy     | 1.0241207     |\n",
      "| policy_loss        | -0.0018022452 |\n",
      "| serial_timesteps   | 16128         |\n",
      "| time_elapsed       | 2.83e+03      |\n",
      "| total_timesteps    | 16128         |\n",
      "| value_loss         | 0.35938996    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000599529   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 127           |\n",
      "| policy_entropy     | 0.97621953    |\n",
      "| policy_loss        | -0.0037572607 |\n",
      "| serial_timesteps   | 16256         |\n",
      "| time_elapsed       | 2.83e+03      |\n",
      "| total_timesteps    | 16256         |\n",
      "| value_loss         | 2.5929434     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005650362  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 128           |\n",
      "| policy_entropy     | 0.9401492     |\n",
      "| policy_loss        | -0.0015644057 |\n",
      "| serial_timesteps   | 16384         |\n",
      "| time_elapsed       | 2.84e+03      |\n",
      "| total_timesteps    | 16384         |\n",
      "| value_loss         | 0.5834549     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=16500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00081508677 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 129           |\n",
      "| policy_entropy     | 0.9049834     |\n",
      "| policy_loss        | -0.0026118453 |\n",
      "| serial_timesteps   | 16512         |\n",
      "| time_elapsed       | 2.84e+03      |\n",
      "| total_timesteps    | 16512         |\n",
      "| value_loss         | 0.19757669    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004843199 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 130          |\n",
      "| policy_entropy     | 0.83719146   |\n",
      "| policy_loss        | 0.0010868122 |\n",
      "| serial_timesteps   | 16640        |\n",
      "| time_elapsed       | 2.9e+03      |\n",
      "| total_timesteps    | 16640        |\n",
      "| value_loss         | 0.27960202   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0005997876 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 131          |\n",
      "| policy_entropy     | 0.8563374    |\n",
      "| policy_loss        | -0.005481732 |\n",
      "| serial_timesteps   | 16768        |\n",
      "| time_elapsed       | 2.91e+03     |\n",
      "| total_timesteps    | 16768        |\n",
      "| value_loss         | 1.395796     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00055773393 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 132           |\n",
      "| policy_entropy     | 0.8746898     |\n",
      "| policy_loss        | -0.0026977889 |\n",
      "| serial_timesteps   | 16896         |\n",
      "| time_elapsed       | 2.91e+03      |\n",
      "| total_timesteps    | 16896         |\n",
      "| value_loss         | 0.2367242     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00026845315 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 133           |\n",
      "| policy_entropy     | 0.8364196     |\n",
      "| policy_loss        | 0.0007817948  |\n",
      "| serial_timesteps   | 17024         |\n",
      "| time_elapsed       | 2.92e+03      |\n",
      "| total_timesteps    | 17024         |\n",
      "| value_loss         | 0.24853623    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.001207611  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 134          |\n",
      "| policy_entropy     | 0.81415904   |\n",
      "| policy_loss        | -0.008049724 |\n",
      "| serial_timesteps   | 17152        |\n",
      "| time_elapsed       | 2.98e+03     |\n",
      "| total_timesteps    | 17152        |\n",
      "| value_loss         | 0.3341848    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00025411445 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 135           |\n",
      "| policy_entropy     | 0.7629919     |\n",
      "| policy_loss        | 0.0018292288  |\n",
      "| serial_timesteps   | 17280         |\n",
      "| time_elapsed       | 2.98e+03      |\n",
      "| total_timesteps    | 17280         |\n",
      "| value_loss         | 0.46537334    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00046073878  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 5.96e-08       |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 136            |\n",
      "| policy_entropy     | 0.7864516      |\n",
      "| policy_loss        | -0.00046045438 |\n",
      "| serial_timesteps   | 17408          |\n",
      "| time_elapsed       | 2.99e+03       |\n",
      "| total_timesteps    | 17408          |\n",
      "| value_loss         | 0.49061003     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=17500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 7.571017e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 137           |\n",
      "| policy_entropy     | 0.8186627     |\n",
      "| policy_loss        | 0.00097088865 |\n",
      "| serial_timesteps   | 17536         |\n",
      "| time_elapsed       | 2.99e+03      |\n",
      "| total_timesteps    | 17536         |\n",
      "| value_loss         | 1.2465293     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00024689164 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 138           |\n",
      "| policy_entropy     | 0.8303504     |\n",
      "| policy_loss        | -0.0017900495 |\n",
      "| serial_timesteps   | 17664         |\n",
      "| time_elapsed       | 3.05e+03      |\n",
      "| total_timesteps    | 17664         |\n",
      "| value_loss         | 0.605182      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0012220977  |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 139           |\n",
      "| policy_entropy     | 0.8872451     |\n",
      "| policy_loss        | -0.0026636505 |\n",
      "| serial_timesteps   | 17792         |\n",
      "| time_elapsed       | 3.06e+03      |\n",
      "| total_timesteps    | 17792         |\n",
      "| value_loss         | 0.19958492    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00047731653 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 140           |\n",
      "| policy_entropy     | 0.94172186    |\n",
      "| policy_loss        | 0.0029847417  |\n",
      "| serial_timesteps   | 17920         |\n",
      "| time_elapsed       | 3.06e+03      |\n",
      "| total_timesteps    | 17920         |\n",
      "| value_loss         | 2.001143      |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015028456 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 141           |\n",
      "| policy_entropy     | 0.9465951     |\n",
      "| policy_loss        | -0.0018621287 |\n",
      "| serial_timesteps   | 18048         |\n",
      "| time_elapsed       | 3.07e+03      |\n",
      "| total_timesteps    | 18048         |\n",
      "| value_loss         | 0.20681942    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00022789756 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 142           |\n",
      "| policy_entropy     | 0.9661599     |\n",
      "| policy_loss        | -0.0007416224 |\n",
      "| serial_timesteps   | 18176         |\n",
      "| time_elapsed       | 3.12e+03      |\n",
      "| total_timesteps    | 18176         |\n",
      "| value_loss         | 0.41890976    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00030081242 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 143           |\n",
      "| policy_entropy     | 0.9810726     |\n",
      "| policy_loss        | -0.002677155  |\n",
      "| serial_timesteps   | 18304         |\n",
      "| time_elapsed       | 3.13e+03      |\n",
      "| total_timesteps    | 18304         |\n",
      "| value_loss         | 0.35707182    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00022044615 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 144           |\n",
      "| policy_entropy     | 0.9591711     |\n",
      "| policy_loss        | 1.8615625e-05 |\n",
      "| serial_timesteps   | 18432         |\n",
      "| time_elapsed       | 3.13e+03      |\n",
      "| total_timesteps    | 18432         |\n",
      "| value_loss         | 1.1913338     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=18500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| approxkl           | 7.103821e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 2            |\n",
      "| n_updates          | 145          |\n",
      "| policy_entropy     | 0.941857     |\n",
      "| policy_loss        | -0.001431385 |\n",
      "| serial_timesteps   | 18560        |\n",
      "| time_elapsed       | 3.14e+03     |\n",
      "| total_timesteps    | 18560        |\n",
      "| value_loss         | 0.97621197   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00091534207 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 146           |\n",
      "| policy_entropy     | 0.9459921     |\n",
      "| policy_loss        | -0.004989978  |\n",
      "| serial_timesteps   | 18688         |\n",
      "| time_elapsed       | 3.2e+03       |\n",
      "| total_timesteps    | 18688         |\n",
      "| value_loss         | 0.22781       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00027533338 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 147           |\n",
      "| policy_entropy     | 0.94570416    |\n",
      "| policy_loss        | 0.0017997441  |\n",
      "| serial_timesteps   | 18816         |\n",
      "| time_elapsed       | 3.2e+03       |\n",
      "| total_timesteps    | 18816         |\n",
      "| value_loss         | 0.6523931     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002671013 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 148          |\n",
      "| policy_entropy     | 0.9192649    |\n",
      "| policy_loss        | 0.0006019686 |\n",
      "| serial_timesteps   | 18944        |\n",
      "| time_elapsed       | 3.21e+03     |\n",
      "| total_timesteps    | 18944        |\n",
      "| value_loss         | 1.7037059    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00052767433 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 149           |\n",
      "| policy_entropy     | 0.9298614     |\n",
      "| policy_loss        | -0.0029358678 |\n",
      "| serial_timesteps   | 19072         |\n",
      "| time_elapsed       | 3.21e+03      |\n",
      "| total_timesteps    | 19072         |\n",
      "| value_loss         | 0.33949354    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008475189  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 150           |\n",
      "| policy_entropy     | 0.98564935    |\n",
      "| policy_loss        | -0.0018778779 |\n",
      "| serial_timesteps   | 19200         |\n",
      "| time_elapsed       | 3.27e+03      |\n",
      "| total_timesteps    | 19200         |\n",
      "| value_loss         | 0.42512423    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.002764933  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 151          |\n",
      "| policy_entropy     | 1.0447046    |\n",
      "| policy_loss        | -0.014565883 |\n",
      "| serial_timesteps   | 19328        |\n",
      "| time_elapsed       | 3.28e+03     |\n",
      "| total_timesteps    | 19328        |\n",
      "| value_loss         | 0.32196108   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0031228473  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 152           |\n",
      "| policy_entropy     | 1.1262741     |\n",
      "| policy_loss        | -0.0059794327 |\n",
      "| serial_timesteps   | 19456         |\n",
      "| time_elapsed       | 3.28e+03      |\n",
      "| total_timesteps    | 19456         |\n",
      "| value_loss         | 1.6858869     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=19500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019650697 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 153           |\n",
      "| policy_entropy     | 1.1436869     |\n",
      "| policy_loss        | 0.00040955585 |\n",
      "| serial_timesteps   | 19584         |\n",
      "| time_elapsed       | 3.29e+03      |\n",
      "| total_timesteps    | 19584         |\n",
      "| value_loss         | 0.3117919     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006549955  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 154           |\n",
      "| policy_entropy     | 1.1275723     |\n",
      "| policy_loss        | -0.0038535648 |\n",
      "| serial_timesteps   | 19712         |\n",
      "| time_elapsed       | 3.35e+03      |\n",
      "| total_timesteps    | 19712         |\n",
      "| value_loss         | 0.36913708    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00044828578 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 155           |\n",
      "| policy_entropy     | 1.1309037     |\n",
      "| policy_loss        | 0.002029635   |\n",
      "| serial_timesteps   | 19840         |\n",
      "| time_elapsed       | 3.35e+03      |\n",
      "| total_timesteps    | 19840         |\n",
      "| value_loss         | 0.88256395    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00045308884 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 156           |\n",
      "| policy_entropy     | 1.1357359     |\n",
      "| policy_loss        | -0.0012692699 |\n",
      "| serial_timesteps   | 19968         |\n",
      "| time_elapsed       | 3.36e+03      |\n",
      "| total_timesteps    | 19968         |\n",
      "| value_loss         | 0.26461914    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 4.8803307e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 157           |\n",
      "| policy_entropy     | 1.1509564     |\n",
      "| policy_loss        | 0.0011549173  |\n",
      "| serial_timesteps   | 20096         |\n",
      "| time_elapsed       | 3.36e+03      |\n",
      "| total_timesteps    | 20096         |\n",
      "| value_loss         | 0.3944068     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00084309146 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 158           |\n",
      "| policy_entropy     | 1.1365591     |\n",
      "| policy_loss        | -0.0029125442 |\n",
      "| serial_timesteps   | 20224         |\n",
      "| time_elapsed       | 3.42e+03      |\n",
      "| total_timesteps    | 20224         |\n",
      "| value_loss         | 0.6210415     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000116196214 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.19e-07      |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 159            |\n",
      "| policy_entropy     | 1.1274153      |\n",
      "| policy_loss        | 0.00053324737  |\n",
      "| serial_timesteps   | 20352          |\n",
      "| time_elapsed       | 3.43e+03       |\n",
      "| total_timesteps    | 20352          |\n",
      "| value_loss         | 0.70518816     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017997943 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 160           |\n",
      "| policy_entropy     | 1.1372204     |\n",
      "| policy_loss        | -0.0006305644 |\n",
      "| serial_timesteps   | 20480         |\n",
      "| time_elapsed       | 3.43e+03      |\n",
      "| total_timesteps    | 20480         |\n",
      "| value_loss         | 0.7753036     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=20500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0019695598 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 2            |\n",
      "| n_updates          | 161          |\n",
      "| policy_entropy     | 1.1243963    |\n",
      "| policy_loss        | -0.006715563 |\n",
      "| serial_timesteps   | 20608        |\n",
      "| time_elapsed       | 3.44e+03     |\n",
      "| total_timesteps    | 20608        |\n",
      "| value_loss         | 0.40543303   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0019591108  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 162           |\n",
      "| policy_entropy     | 1.1124015     |\n",
      "| policy_loss        | -0.0037423465 |\n",
      "| serial_timesteps   | 20736         |\n",
      "| time_elapsed       | 3.5e+03       |\n",
      "| total_timesteps    | 20736         |\n",
      "| value_loss         | 0.28334916    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006548884  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 163           |\n",
      "| policy_entropy     | 1.1063635     |\n",
      "| policy_loss        | -0.0024033703 |\n",
      "| serial_timesteps   | 20864         |\n",
      "| time_elapsed       | 3.5e+03       |\n",
      "| total_timesteps    | 20864         |\n",
      "| value_loss         | 0.4657622     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.000561528  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 164          |\n",
      "| policy_entropy     | 1.1179283    |\n",
      "| policy_loss        | -0.003580123 |\n",
      "| serial_timesteps   | 20992        |\n",
      "| time_elapsed       | 3.51e+03     |\n",
      "| total_timesteps    | 20992        |\n",
      "| value_loss         | 0.9456711    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00015758403  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 2              |\n",
      "| n_updates          | 165            |\n",
      "| policy_entropy     | 1.1221126      |\n",
      "| policy_loss        | -7.1627845e-05 |\n",
      "| serial_timesteps   | 21120          |\n",
      "| time_elapsed       | 3.51e+03       |\n",
      "| total_timesteps    | 21120          |\n",
      "| value_loss         | 0.3673624      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0003271641 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 166          |\n",
      "| policy_entropy     | 1.1519806    |\n",
      "| policy_loss        | 0.0013360898 |\n",
      "| serial_timesteps   | 21248        |\n",
      "| time_elapsed       | 3.57e+03     |\n",
      "| total_timesteps    | 21248        |\n",
      "| value_loss         | 1.364475     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.3701085e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 25             |\n",
      "| n_updates          | 167            |\n",
      "| policy_entropy     | 1.1564244      |\n",
      "| policy_loss        | -0.00091137306 |\n",
      "| serial_timesteps   | 21376          |\n",
      "| time_elapsed       | 3.58e+03       |\n",
      "| total_timesteps    | 21376          |\n",
      "| value_loss         | 2.3065128      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=21500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 3.230674e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 168           |\n",
      "| policy_entropy     | 1.16572       |\n",
      "| policy_loss        | 0.00057526503 |\n",
      "| serial_timesteps   | 21504         |\n",
      "| time_elapsed       | 3.58e+03      |\n",
      "| total_timesteps    | 21504         |\n",
      "| value_loss         | 2.7880712     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00074491673 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 169           |\n",
      "| policy_entropy     | 1.1546304     |\n",
      "| policy_loss        | -0.0025086957 |\n",
      "| serial_timesteps   | 21632         |\n",
      "| time_elapsed       | 3.64e+03      |\n",
      "| total_timesteps    | 21632         |\n",
      "| value_loss         | 0.4709625     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| approxkl           | 0.00012632765   |\n",
      "| clipfrac           | 0.0             |\n",
      "| explained_variance | 0               |\n",
      "| fps                | 25              |\n",
      "| n_updates          | 170             |\n",
      "| policy_entropy     | 1.1447624       |\n",
      "| policy_loss        | -0.000120588695 |\n",
      "| serial_timesteps   | 21760           |\n",
      "| time_elapsed       | 3.64e+03        |\n",
      "| total_timesteps    | 21760           |\n",
      "| value_loss         | 0.86080295      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00091501226 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 171           |\n",
      "| policy_entropy     | 1.1730059     |\n",
      "| policy_loss        | -0.0039658626 |\n",
      "| serial_timesteps   | 21888         |\n",
      "| time_elapsed       | 3.65e+03      |\n",
      "| total_timesteps    | 21888         |\n",
      "| value_loss         | 0.44015417    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0012097233 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 5.96e-08     |\n",
      "| fps                | 2            |\n",
      "| n_updates          | 172          |\n",
      "| policy_entropy     | 1.2050362    |\n",
      "| policy_loss        | -0.002220437 |\n",
      "| serial_timesteps   | 22016        |\n",
      "| time_elapsed       | 3.65e+03     |\n",
      "| total_timesteps    | 22016        |\n",
      "| value_loss         | 0.50332505   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0017427786 |\n",
      "| clipfrac           | 0.005859375  |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 173          |\n",
      "| policy_entropy     | 1.2426066    |\n",
      "| policy_loss        | -0.004613906 |\n",
      "| serial_timesteps   | 22144        |\n",
      "| time_elapsed       | 3.71e+03     |\n",
      "| total_timesteps    | 22144        |\n",
      "| value_loss         | 0.3010148    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0010181264   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 174            |\n",
      "| policy_entropy     | 1.2803564      |\n",
      "| policy_loss        | -0.00069935643 |\n",
      "| serial_timesteps   | 22272          |\n",
      "| time_elapsed       | 3.72e+03       |\n",
      "| total_timesteps    | 22272          |\n",
      "| value_loss         | 0.91721386     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018236498 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 175           |\n",
      "| policy_entropy     | 1.2868772     |\n",
      "| policy_loss        | 0.000285364   |\n",
      "| serial_timesteps   | 22400         |\n",
      "| time_elapsed       | 3.72e+03      |\n",
      "| total_timesteps    | 22400         |\n",
      "| value_loss         | 0.30752075    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=22500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| approxkl           | 6.417438e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 5.96e-08       |\n",
      "| fps                | 2              |\n",
      "| n_updates          | 176            |\n",
      "| policy_entropy     | 1.2907147      |\n",
      "| policy_loss        | -0.00085873075 |\n",
      "| serial_timesteps   | 22528          |\n",
      "| time_elapsed       | 3.73e+03       |\n",
      "| total_timesteps    | 22528          |\n",
      "| value_loss         | 0.49215317     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0022677898 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 177          |\n",
      "| policy_entropy     | 1.2907205    |\n",
      "| policy_loss        | -0.011266325 |\n",
      "| serial_timesteps   | 22656        |\n",
      "| time_elapsed       | 3.79e+03     |\n",
      "| total_timesteps    | 22656        |\n",
      "| value_loss         | 0.29614952   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014129777 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 178          |\n",
      "| policy_entropy     | 1.2606726    |\n",
      "| policy_loss        | 0.003364366  |\n",
      "| serial_timesteps   | 22784        |\n",
      "| time_elapsed       | 3.79e+03     |\n",
      "| total_timesteps    | 22784        |\n",
      "| value_loss         | 0.38875115   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.682654e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 179           |\n",
      "| policy_entropy     | 1.2498374     |\n",
      "| policy_loss        | -0.0009367794 |\n",
      "| serial_timesteps   | 22912         |\n",
      "| time_elapsed       | 3.8e+03       |\n",
      "| total_timesteps    | 22912         |\n",
      "| value_loss         | 0.4978488     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 406.00 +/- 133.34\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00058754307 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 1             |\n",
      "| n_updates          | 180           |\n",
      "| policy_entropy     | 1.2447368     |\n",
      "| policy_loss        | -0.0035625934 |\n",
      "| serial_timesteps   | 23040         |\n",
      "| time_elapsed       | 3.8e+03       |\n",
      "| total_timesteps    | 23040         |\n",
      "| value_loss         | 0.4574582     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.000993051  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 181          |\n",
      "| policy_entropy     | 1.2476958    |\n",
      "| policy_loss        | -0.005073784 |\n",
      "| serial_timesteps   | 23168        |\n",
      "| time_elapsed       | 3.87e+03     |\n",
      "| total_timesteps    | 23168        |\n",
      "| value_loss         | 0.284881     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0005104549 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 182          |\n",
      "| policy_entropy     | 1.2730863    |\n",
      "| policy_loss        | 0.0060157855 |\n",
      "| serial_timesteps   | 23296        |\n",
      "| time_elapsed       | 3.88e+03     |\n",
      "| total_timesteps    | 23296        |\n",
      "| value_loss         | 1.6707445    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.039096e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 24             |\n",
      "| n_updates          | 183            |\n",
      "| policy_entropy     | 1.2761172      |\n",
      "| policy_loss        | -0.00031063572 |\n",
      "| serial_timesteps   | 23424          |\n",
      "| time_elapsed       | 3.88e+03       |\n",
      "| total_timesteps    | 23424          |\n",
      "| value_loss         | 0.7867826      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=23500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00022672693 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 184           |\n",
      "| policy_entropy     | 1.2723236     |\n",
      "| policy_loss        | -0.0034752786 |\n",
      "| serial_timesteps   | 23552         |\n",
      "| time_elapsed       | 3.89e+03      |\n",
      "| total_timesteps    | 23552         |\n",
      "| value_loss         | 1.9201736     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0002906534  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.79e-07      |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 185           |\n",
      "| policy_entropy     | 1.2687912     |\n",
      "| policy_loss        | -0.0048435745 |\n",
      "| serial_timesteps   | 23680         |\n",
      "| time_elapsed       | 3.95e+03      |\n",
      "| total_timesteps    | 23680         |\n",
      "| value_loss         | 0.4572114     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00046015446 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 186           |\n",
      "| policy_entropy     | 1.2547309     |\n",
      "| policy_loss        | 3.37644e-05   |\n",
      "| serial_timesteps   | 23808         |\n",
      "| time_elapsed       | 3.95e+03      |\n",
      "| total_timesteps    | 23808         |\n",
      "| value_loss         | 0.51910424    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038168055 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 187           |\n",
      "| policy_entropy     | 1.244297      |\n",
      "| policy_loss        | -0.0018528325 |\n",
      "| serial_timesteps   | 23936         |\n",
      "| time_elapsed       | 3.96e+03      |\n",
      "| total_timesteps    | 23936         |\n",
      "| value_loss         | 0.40648922    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00096560275 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 188           |\n",
      "| policy_entropy     | 1.2341428     |\n",
      "| policy_loss        | -0.0043017026 |\n",
      "| serial_timesteps   | 24064         |\n",
      "| time_elapsed       | 3.96e+03      |\n",
      "| total_timesteps    | 24064         |\n",
      "| value_loss         | 1.8255179     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00027389848 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 189           |\n",
      "| policy_entropy     | 1.2395115     |\n",
      "| policy_loss        | -0.0032581962 |\n",
      "| serial_timesteps   | 24192         |\n",
      "| time_elapsed       | 4.02e+03      |\n",
      "| total_timesteps    | 24192         |\n",
      "| value_loss         | 0.2007305     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0017149539  |\n",
      "| clipfrac           | 0.021484375   |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 190           |\n",
      "| policy_entropy     | 1.2720405     |\n",
      "| policy_loss        | -0.0089703305 |\n",
      "| serial_timesteps   | 24320         |\n",
      "| time_elapsed       | 4.03e+03      |\n",
      "| total_timesteps    | 24320         |\n",
      "| value_loss         | 2.4076629     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0001408233 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 191          |\n",
      "| policy_entropy     | 1.2927401    |\n",
      "| policy_loss        | 0.0011436337 |\n",
      "| serial_timesteps   | 24448        |\n",
      "| time_elapsed       | 4.03e+03     |\n",
      "| total_timesteps    | 24448        |\n",
      "| value_loss         | 0.33802778   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=24500, episode_reward=40.00 +/- 0.00\n",
      "Episode length: 335.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00094638136 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 2             |\n",
      "| n_updates          | 192           |\n",
      "| policy_entropy     | 1.2770464     |\n",
      "| policy_loss        | -0.006129642  |\n",
      "| serial_timesteps   | 24576         |\n",
      "| time_elapsed       | 4.04e+03      |\n",
      "| total_timesteps    | 24576         |\n",
      "| value_loss         | 0.44082692    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0019521895  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 193           |\n",
      "| policy_entropy     | 1.2402047     |\n",
      "| policy_loss        | -0.0053604054 |\n",
      "| serial_timesteps   | 24704         |\n",
      "| time_elapsed       | 4.1e+03       |\n",
      "| total_timesteps    | 24704         |\n",
      "| value_loss         | 0.26488763    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00085221033 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 194           |\n",
      "| policy_entropy     | 1.1967666     |\n",
      "| policy_loss        | -0.0027098784 |\n",
      "| serial_timesteps   | 24832         |\n",
      "| time_elapsed       | 4.1e+03       |\n",
      "| total_timesteps    | 24832         |\n",
      "| value_loss         | 0.33160043    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0023819807  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 195           |\n",
      "| policy_entropy     | 1.1719048     |\n",
      "| policy_loss        | -0.0063005947 |\n",
      "| serial_timesteps   | 24960         |\n",
      "| time_elapsed       | 4.11e+03      |\n",
      "| total_timesteps    | 24960         |\n",
      "| value_loss         | 1.5221188     |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import gym_gvgai\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "#from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import ActorCriticPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import SAC\n",
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "\n",
    "def show_state(env, step=0, name=\"\", info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name,step,info))\n",
    "    plt.axis('off')\n",
    "              \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "env = gym.make('gvgai-aliens-lvl3-v0')\n",
    "    \n",
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "log_path='./logs/', eval_freq=500,\n",
    "deterministic=True, render=False)\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=25000,callback=eval_callback)\n",
    "model.save(\"ppo2_aliens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
