{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host 127.0.0.1 at port 64315 ...\n",
      "Client connected to server [OK]\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9790>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9790>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9b10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1469d9b10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/trpo_mpi/trpo_mpi.py:192: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/trpo_mpi/trpo_mpi.py:266: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x14696ca90> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x10fd93f90>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=-0.40 +/- 1.20\n",
      "Episode length: 514.40 +/- 273.33\n",
      "New best mean reward!\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 387.60 +/- 207.36\n",
      "\u001b[35mdone in 175.149 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.973 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0771          0\n",
      "         1     0.0371     0.0163\n",
      "         2     0.0138     0.0382\n",
      "         3      0.164      0.129\n",
      "         4     0.0829      0.348\n",
      "         5     0.0355      0.619\n",
      "         6     0.0704      0.858\n",
      "         7     0.0264       1.55\n",
      "         8     0.0644       1.59\n",
      "         9      0.173       2.93\n",
      "        10     0.0363       3.05\n",
      "\u001b[35mdone in 5.680 seconds\u001b[0m\n",
      "Expected: 0.070 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.587 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 109          |\n",
      "| EpRewMean               | 14           |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 1            |\n",
      "| TimeElapsed             | 195          |\n",
      "| TimestepsSoFar          | 1024         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.3834498    |\n",
      "| explained_variance_t... | -0.0432      |\n",
      "| meankl                  | 0.0029773377 |\n",
      "| optimgain               | 0.0019313951 |\n",
      "| surrgain                | 0.0019313951 |\n",
      "------------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 404.60 +/- 158.33\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 443.00 +/- 98.06\n",
      "\u001b[35mdone in 166.130 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.890 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       62.8          0\n",
      "         1      0.355   8.87e-05\n",
      "         2       15.5    0.00118\n",
      "         3      0.344    0.00429\n",
      "         4      0.632    0.00431\n",
      "         5        142       1.32\n",
      "         6         37       1.33\n",
      "         7       3.98       1.34\n",
      "         8        144       12.7\n",
      "         9       20.2       12.7\n",
      "        10        317       12.7\n",
      "\u001b[35mdone in 5.189 seconds\u001b[0m\n",
      "Expected: 0.303 Actual: -0.002\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.303 Actual: -0.002\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.303 Actual: -0.002\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.303 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.303 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.828 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 478           |\n",
      "| EpRewMean               | 48.8          |\n",
      "| EpThisIter              | 3             |\n",
      "| EpisodesSoFar           | 4             |\n",
      "| TimeElapsed             | 391           |\n",
      "| TimestepsSoFar          | 2048          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.3839242     |\n",
      "| explained_variance_t... | 1.19e-07      |\n",
      "| meankl                  | 0.00090445654 |\n",
      "| optimgain               | 0.0018319851  |\n",
      "| surrgain                | 0.0018319851  |\n",
      "-------------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=-0.60 +/- 0.80\n",
      "Episode length: 460.40 +/- 145.62\n",
      "Eval num_timesteps=2048, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 484.00 +/- 108.75\n",
      "\u001b[35mdone in 177.101 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.443 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       46.3          0\n",
      "         1       2.41    0.00012\n",
      "         2      0.767   0.000139\n",
      "         3       8.08     0.0482\n",
      "         4        241     0.0534\n",
      "         5    2.8e+03      0.581\n",
      "         6       2.35      0.702\n",
      "         7   1.46e+04       1.23\n",
      "         8        610       2.13\n",
      "         9       1.97       2.15\n",
      "        10   1.94e+03       2.21\n",
      "\u001b[35mdone in 5.297 seconds\u001b[0m\n",
      "Expected: 0.176 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.730 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 443          |\n",
      "| EpRewMean               | 44.4         |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 5            |\n",
      "| TimeElapsed             | 586          |\n",
      "| TimestepsSoFar          | 3072         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.3847468    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.0024481853 |\n",
      "| optimgain               | 0.00171097   |\n",
      "| surrgain                | 0.00171097   |\n",
      "------------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 593.40 +/- 145.37\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 659.60 +/- 53.06\n",
      "\u001b[35mdone in 238.205 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.425 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0602          0\n",
      "         1   0.000166     0.0265\n",
      "         2   1.68e-07     0.0266\n",
      "         3   1.22e-09     0.0266\n",
      "         4   2.21e-14     0.0268\n",
      "\u001b[35mdone in 2.171 seconds\u001b[0m\n",
      "Expected: 0.011 Actual: 0.012\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.712 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 538         |\n",
      "| EpRewMean               | 54.3        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 7           |\n",
      "| TimeElapsed             | 839         |\n",
      "| TimestepsSoFar          | 4096        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.371206    |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.01018833  |\n",
      "| optimgain               | 0.011673327 |\n",
      "| surrgain                | 0.011673327 |\n",
      "-----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 451.20 +/- 133.20\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 448.40 +/- 130.55\n",
      "\u001b[35mdone in 180.272 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.204 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.144          0\n",
      "         1      0.661      0.219\n",
      "         2       6.53       10.9\n",
      "         3      0.214       13.7\n",
      "         4   0.000781       13.7\n",
      "         5   1.75e-05       14.2\n",
      "         6    9.8e-08       14.2\n",
      "         7   2.93e-13       14.2\n",
      "\u001b[35mdone in 4.760 seconds\u001b[0m\n",
      "Expected: 0.310 Actual: -0.004\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.310 Actual: 0.000\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.887 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 559           |\n",
      "| EpRewMean               | 54.8          |\n",
      "| EpThisIter              | 1             |\n",
      "| EpisodesSoFar           | 8             |\n",
      "| TimeElapsed             | 1.05e+03      |\n",
      "| TimestepsSoFar          | 5120          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.3713627     |\n",
      "| explained_variance_t... | -1.19e-07     |\n",
      "| meankl                  | 5.8286816e-05 |\n",
      "| optimgain               | 9.3708746e-05 |\n",
      "| surrgain                | 9.3708746e-05 |\n",
      "-------------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 422.20 +/- 163.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 542.20 +/- 132.76\n",
      "\u001b[35mdone in 186.696 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.541 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0162          0\n",
      "         1     0.0356     0.0417\n",
      "         2       1.17       1.46\n",
      "         3      0.752       9.73\n",
      "         4   2.24e-06       10.5\n",
      "         5   0.000214       10.5\n",
      "         6   6.69e-06       10.5\n",
      "         7   3.62e-08       10.5\n",
      "         8   7.14e-10       10.5\n",
      "         9   2.48e-11       10.5\n",
      "\u001b[35mdone in 4.752 seconds\u001b[0m\n",
      "Expected: 0.149 Actual: -0.000\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.149 Actual: 0.000\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.768 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 662           |\n",
      "| EpRewMean               | 64            |\n",
      "| EpThisIter              | 1             |\n",
      "| EpisodesSoFar           | 9             |\n",
      "| TimeElapsed             | 1.26e+03      |\n",
      "| TimestepsSoFar          | 6144          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.3827921     |\n",
      "| explained_variance_t... | -0.000296     |\n",
      "| meankl                  | 0.005585188   |\n",
      "| optimgain               | 4.2000785e-05 |\n",
      "| surrgain                | 4.2000785e-05 |\n",
      "-------------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 550.00 +/- 156.12\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 554.20 +/- 165.94\n",
      "\u001b[35mdone in 214.870 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.605 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.192          0\n",
      "         1    0.00112     0.0491\n",
      "         2     0.0033     0.0522\n",
      "         3      0.198       1.44\n",
      "         4   7.04e-11       2.89\n",
      "\u001b[35mdone in 2.256 seconds\u001b[0m\n",
      "Expected: 0.046 Actual: 0.013\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.404 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 662          |\n",
      "| EpRewMean               | 64           |\n",
      "| EpThisIter              | 0            |\n",
      "| EpisodesSoFar           | 9            |\n",
      "| TimeElapsed             | 1.49e+03     |\n",
      "| TimestepsSoFar          | 7168         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.3790127    |\n",
      "| explained_variance_t... | 1.19e-07     |\n",
      "| meankl                  | 0.0058421455 |\n",
      "| optimgain               | 0.013089253  |\n",
      "| surrgain                | 0.013089253  |\n",
      "------------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 352.60 +/- 115.01\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 422.40 +/- 148.18\n",
      "\u001b[35mdone in 155.065 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.234 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0268          0\n",
      "         1   0.000241     0.0173\n",
      "         2   8.55e-08     0.0175\n",
      "         3      2e-14     0.0175\n",
      "\u001b[35mdone in 1.689 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.072 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 662         |\n",
      "| EpRewMean               | 64          |\n",
      "| EpThisIter              | 0           |\n",
      "| EpisodesSoFar           | 9           |\n",
      "| TimeElapsed             | 1.66e+03    |\n",
      "| TimestepsSoFar          | 8192        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.3655697   |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.009991181 |\n",
      "| optimgain               | 0.007549118 |\n",
      "| surrgain                | 0.007549118 |\n",
      "-----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=33.20 +/- 15.22\n",
      "Episode length: 358.00 +/- 142.98\n",
      "New best mean reward!\n",
      "Eval num_timesteps=8192, episode_reward=38.60 +/- 6.80\n",
      "Episode length: 412.40 +/- 71.20\n",
      "New best mean reward!\n",
      "\u001b[35mdone in 154.161 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.089 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0886          0\n",
      "         1    0.00187     0.0344\n",
      "         2   3.44e-05     0.0354\n",
      "         3   2.77e-07     0.0354\n",
      "         4   1.27e-11     0.0635\n",
      "\u001b[35mdone in 2.195 seconds\u001b[0m\n",
      "Expected: 0.014 Actual: 0.015\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.027 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 877         |\n",
      "| EpRewMean               | 85.1        |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 10          |\n",
      "| TimeElapsed             | 1.83e+03    |\n",
      "| TimestepsSoFar          | 9216        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.352869    |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.010360305 |\n",
      "| optimgain               | 0.015295306 |\n",
      "| surrgain                | 0.015295306 |\n",
      "-----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 229.00 +/- 57.05\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 478.80 +/- 182.56\n",
      "\u001b[35mdone in 149.751 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.570 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.109          0\n",
      "         1   0.000627     0.0299\n",
      "         2   1.49e-06     0.0304\n",
      "         3    7.1e-14     0.0304\n",
      "\u001b[35mdone in 1.935 seconds\u001b[0m\n",
      "Expected: 0.014 Actual: 0.014\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.687 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 877         |\n",
      "| EpRewMean               | 85.1        |\n",
      "| EpThisIter              | 0           |\n",
      "| EpisodesSoFar           | 10          |\n",
      "| TimeElapsed             | 1.99e+03    |\n",
      "| TimestepsSoFar          | 10240       |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.3336651   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.01008893  |\n",
      "| optimgain               | 0.014297205 |\n",
      "| surrgain                | 0.014297205 |\n",
      "-----------------------------------------\n",
      "Connecting to host 127.0.0.1 at port 54468 ...\n",
      "Client connected to server [OK]\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-aliens-lvl1-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x10fd93f90>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=41.00 +/- 2.00\n",
      "Episode length: 431.80 +/- 32.40\n",
      "New best mean reward!\n",
      "Eval num_timesteps=0, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "New best mean reward!\n",
      "\u001b[35mdone in 176.642 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.185 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00925          0\n",
      "         1   0.000317    0.00982\n",
      "         2   1.84e-05     0.0104\n",
      "         3   7.31e-15     0.0105\n",
      "\u001b[35mdone in 1.683 seconds\u001b[0m\n",
      "Expected: 0.004 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.067 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 298          |\n",
      "| EpRewMean               | 38.5         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 2            |\n",
      "| TimeElapsed             | 191          |\n",
      "| TimestepsSoFar          | 1024         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.3350387    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.010431921  |\n",
      "| optimgain               | 0.0047275336 |\n",
      "| surrgain                | 0.0047275336 |\n",
      "------------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=1024, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "\u001b[35mdone in 179.498 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.427 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00644          0\n",
      "         1   0.000262     0.0079\n",
      "         2   5.28e-06    0.00883\n",
      "         3   5.57e-15    0.00885\n",
      "\u001b[35mdone in 1.667 seconds\u001b[0m\n",
      "Expected: 0.004 Actual: 0.004\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.986 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 460          |\n",
      "| EpRewMean               | 48.2         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 4            |\n",
      "| TimeElapsed             | 385          |\n",
      "| TimestepsSoFar          | 2048         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.3042144    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.00986675   |\n",
      "| optimgain               | 0.0036036016 |\n",
      "| surrgain                | 0.0036036016 |\n",
      "------------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=38.60 +/- 6.80\n",
      "Episode length: 412.40 +/- 71.20\n",
      "Eval num_timesteps=2048, episode_reward=37.40 +/- 9.20\n",
      "Episode length: 403.00 +/- 90.00\n",
      "\u001b[35mdone in 157.815 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.678 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0428          0\n",
      "         1   0.000781     0.0193\n",
      "         2   7.75e-05       0.02\n",
      "         3   3.28e-14     0.0202\n",
      "\u001b[35mdone in 2.068 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 9.169 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 475         |\n",
      "| EpRewMean               | 46.3        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 6           |\n",
      "| TimeElapsed             | 560         |\n",
      "| TimestepsSoFar          | 3072        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.3165482   |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.010237095 |\n",
      "| optimgain               | 0.009376403 |\n",
      "| surrgain                | 0.009376403 |\n",
      "-----------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 461.20 +/- 272.44\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 556.20 +/- 224.96\n",
      "\u001b[35mdone in 196.225 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.334 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00312          0\n",
      "         1   0.000121    0.00558\n",
      "         2   1.51e-05    0.00603\n",
      "         3   2.72e-15    0.00614\n",
      "\u001b[35mdone in 1.825 seconds\u001b[0m\n",
      "Expected: 0.003 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.001 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 470          |\n",
      "| EpRewMean               | 44.6         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 8            |\n",
      "| TimeElapsed             | 771          |\n",
      "| TimestepsSoFar          | 4096         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.3048153    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.00978863   |\n",
      "| optimgain               | 0.0024894462 |\n",
      "| surrgain                | 0.0024894462 |\n",
      "------------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 502.20 +/- 228.35\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 596.40 +/- 229.96\n",
      "\u001b[35mdone in 208.334 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.531 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0247          0\n",
      "         1    0.00152     0.0164\n",
      "         2   5.24e-05     0.0179\n",
      "         3   1.94e-14      0.018\n",
      "\u001b[35mdone in 2.970 seconds\u001b[0m\n",
      "Expected: 0.007 Actual: 0.007\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 11.194 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 512         |\n",
      "| EpRewMean               | 46.2        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 10          |\n",
      "| TimeElapsed             | 998         |\n",
      "| TimestepsSoFar          | 5120        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.3305523   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009830476 |\n",
      "| optimgain               | 0.007229395 |\n",
      "| surrgain                | 0.007229395 |\n",
      "-----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 426.40 +/- 247.40\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 482.00 +/- 203.79\n",
      "\u001b[35mdone in 173.641 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.500 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0359          0\n",
      "         1    0.00108     0.0181\n",
      "         2   1.55e-05     0.0191\n",
      "         3   3.17e-14     0.0192\n",
      "\u001b[35mdone in 2.077 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.920 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 550         |\n",
      "| EpRewMean               | 47.1        |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 11          |\n",
      "| TimeElapsed             | 1.19e+03    |\n",
      "| TimestepsSoFar          | 6144        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.339615    |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010253872 |\n",
      "| optimgain               | 0.008761225 |\n",
      "| surrgain                | 0.008761225 |\n",
      "-----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 577.80 +/- 211.29\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 442.60 +/- 129.73\n",
      "\u001b[35mdone in 197.667 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.240 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0503          0\n",
      "         1    0.00159     0.0237\n",
      "         2   7.31e-06     0.0247\n",
      "         3   3.36e-14     0.0247\n",
      "\u001b[35mdone in 1.760 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.010\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.312 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 512         |\n",
      "| EpRewMean               | 44.8        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 13          |\n",
      "| TimeElapsed             | 1.4e+03     |\n",
      "| TimestepsSoFar          | 7168        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.362976    |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009854987 |\n",
      "| optimgain               | 0.010254653 |\n",
      "| surrgain                | 0.010254653 |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 590.80 +/- 140.14\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 631.60 +/- 192.11\n",
      "\u001b[35mdone in 225.009 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 3.526 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00804          0\n",
      "         1   0.000205    0.00967\n",
      "         2   1.65e-06       0.01\n",
      "         3   6.05e-15       0.01\n",
      "\u001b[35mdone in 2.213 seconds\u001b[0m\n",
      "Expected: 0.004 Actual: 0.004\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 9.634 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 526          |\n",
      "| EpRewMean               | 45           |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 14           |\n",
      "| TimeElapsed             | 1.64e+03     |\n",
      "| TimestepsSoFar          | 8192         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.3247682    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.009713659  |\n",
      "| optimgain               | 0.0040386845 |\n",
      "| surrgain                | 0.0040386845 |\n",
      "------------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 582.40 +/- 132.62\n",
      "Eval num_timesteps=8192, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 543.80 +/- 206.69\n",
      "\u001b[35mdone in 205.113 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.177 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0363          0\n",
      "         1    0.00137     0.0184\n",
      "         2   2.65e-05     0.0197\n",
      "         3   2.74e-14     0.0197\n",
      "\u001b[35mdone in 1.748 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 11.802 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 534         |\n",
      "| EpRewMean               | 44.2        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 16          |\n",
      "| TimeElapsed             | 1.87e+03    |\n",
      "| TimestepsSoFar          | 9216        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.3153385   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010429663 |\n",
      "| optimgain               | 0.009114391 |\n",
      "| surrgain                | 0.009114391 |\n",
      "-----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 426.00 +/- 169.83\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 641.40 +/- 226.29\n",
      "\u001b[35mdone in 201.214 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.547 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0022          0\n",
      "         1   0.000173    0.00445\n",
      "         2    2.1e-06     0.0054\n",
      "         3   2.35e-15    0.00542\n",
      "\u001b[35mdone in 1.947 seconds\u001b[0m\n",
      "Expected: 0.002 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.570 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 560         |\n",
      "| EpRewMean               | 44.3        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 18          |\n",
      "| TimeElapsed             | 2.09e+03    |\n",
      "| TimestepsSoFar          | 10240       |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.2764115   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009875847 |\n",
      "| optimgain               | 0.002128616 |\n",
      "| surrgain                | 0.002128616 |\n",
      "-----------------------------------------\n",
      "Connecting to host 127.0.0.1 at port 54762 ...\n",
      "Client connected to server [OK]\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-aliens-lvl2-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x10fd93f90>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 437.40 +/- 205.44\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 399.20 +/- 205.34\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 588.80 +/- 138.94\n",
      "\u001b[35mdone in 258.661 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.374 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00296          0\n",
      "         1   0.000229    0.00501\n",
      "         2   2.25e-05    0.00613\n",
      "         3   2.78e-15    0.00631\n",
      "\u001b[35mdone in 1.798 seconds\u001b[0m\n",
      "Expected: 0.002 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.453 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 401          |\n",
      "| EpRewMean               | 31.5         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 2            |\n",
      "| TimeElapsed             | 274          |\n",
      "| TimestepsSoFar          | 1024         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.2507687    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.01014899   |\n",
      "| optimgain               | 0.0025489633 |\n",
      "| surrgain                | 0.0025489633 |\n",
      "------------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 428.00 +/- 170.51\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 571.40 +/- 139.48\n",
      "\u001b[35mdone in 191.502 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.368 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0139          0\n",
      "         1    0.00321     0.0179\n",
      "         2   0.000694      0.023\n",
      "         3   6.12e-11     0.0244\n",
      "\u001b[35mdone in 2.230 seconds\u001b[0m\n",
      "Expected: 0.007 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.985 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 384         |\n",
      "| EpRewMean               | 32.8        |\n",
      "| EpThisIter              | 3           |\n",
      "| EpisodesSoFar           | 5           |\n",
      "| TimeElapsed             | 482         |\n",
      "| TimestepsSoFar          | 2048        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.2628678   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010192036 |\n",
      "| optimgain               | 0.007520159 |\n",
      "| surrgain                | 0.007520159 |\n",
      "-----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 497.40 +/- 263.53\n",
      "Eval num_timesteps=2048, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 633.00 +/- 140.77\n",
      "\u001b[35mdone in 209.194 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.117 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.108          0\n",
      "         1    0.00131     0.0249\n",
      "         2    0.00028     0.0256\n",
      "         3    2.7e-06     0.0258\n",
      "         4   3.98e-12     0.0258\n",
      "\u001b[35mdone in 2.202 seconds\u001b[0m\n",
      "Expected: 0.013 Actual: 0.012\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.874 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 354         |\n",
      "| EpRewMean               | 29.9        |\n",
      "| EpThisIter              | 3           |\n",
      "| EpisodesSoFar           | 8           |\n",
      "| TimeElapsed             | 706         |\n",
      "| TimestepsSoFar          | 3072        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.2773647   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009807257 |\n",
      "| optimgain               | 0.012348797 |\n",
      "| surrgain                | 0.012348797 |\n",
      "-----------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=37.40 +/- 9.20\n",
      "Episode length: 402.80 +/- 90.40\n",
      "Eval num_timesteps=3072, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "\u001b[35mdone in 169.100 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.204 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0287          0\n",
      "         1      0.011      0.032\n",
      "         2     0.0907      0.135\n",
      "         3      0.326       0.76\n",
      "         4   4.81e-09       8.49\n",
      "         5   5.32e-10       8.49\n",
      "         6   4.08e-11       8.49\n",
      "\u001b[35mdone in 3.338 seconds\u001b[0m\n",
      "Expected: 0.120 Actual: 0.006\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.120 Actual: 0.005\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.120 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.347 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 375          |\n",
      "| EpRewMean               | 31.6         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 10           |\n",
      "| TimeElapsed             | 895          |\n",
      "| TimestepsSoFar          | 4096         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.320938     |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.013095785  |\n",
      "| optimgain               | 0.0048162797 |\n",
      "| surrgain                | 0.0048162797 |\n",
      "------------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 741.80 +/- 59.45\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 595.40 +/- 232.59\n",
      "\u001b[35mdone in 241.365 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 3.412 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00998          0\n",
      "         1   0.000598    0.00909\n",
      "         2   1.04e-05     0.0105\n",
      "         3   9.54e-15     0.0105\n",
      "\u001b[35mdone in 1.988 seconds\u001b[0m\n",
      "Expected: 0.004 Actual: 0.004\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 11.236 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 414         |\n",
      "| EpRewMean               | 33.7        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 12          |\n",
      "| TimeElapsed             | 1.16e+03    |\n",
      "| TimestepsSoFar          | 5120        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.3297378   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010020744 |\n",
      "| optimgain               | 0.004473718 |\n",
      "| surrgain                | 0.004473718 |\n",
      "-----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=5120, episode_reward=37.40 +/- 9.20\n",
      "Episode length: 403.00 +/- 90.00\n",
      "\u001b[35mdone in 2053.538 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.688 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0547          0\n",
      "         1   0.000259     0.0195\n",
      "         2   2.25e-06     0.0197\n",
      "         3   2.65e-14     0.0197\n",
      "\u001b[35mdone in 1.702 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.010\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 2390.131 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 412         |\n",
      "| EpRewMean               | 34          |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 13          |\n",
      "| TimeElapsed             | 5.61e+03    |\n",
      "| TimestepsSoFar          | 6144        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.2902526   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010196446 |\n",
      "| optimgain               | 0.009854985 |\n",
      "| surrgain                | 0.009854985 |\n",
      "-----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=6144, episode_reward=39.80 +/- 4.40\n",
      "Episode length: 422.00 +/- 52.00\n",
      "\u001b[35mdone in 171.374 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.196 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0393          0\n",
      "         1    0.00542     0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2   4.27e-05     0.0266\n",
      "         3   2.78e-14     0.0267\n",
      "\u001b[35mdone in 1.677 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.010\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 8.578 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 466         |\n",
      "| EpRewMean               | 37.3        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 15          |\n",
      "| TimeElapsed             | 5.79e+03    |\n",
      "| TimestepsSoFar          | 7168        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.2796478   |\n",
      "| explained_variance_t... | 5.96e-08    |\n",
      "| meankl                  | 0.010061457 |\n",
      "| optimgain               | 0.010039909 |\n",
      "| surrgain                | 0.010039909 |\n",
      "-----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=7168, episode_reward=37.40 +/- 9.20\n",
      "Episode length: 403.00 +/- 90.00\n",
      "\u001b[35mdone in 3960.411 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.217 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.018          0\n",
      "         1   0.000135     0.0109\n",
      "         2   3.54e-07     0.0111\n",
      "         3    1.7e-12     0.0111\n",
      "\u001b[35mdone in 1.661 seconds\u001b[0m\n",
      "Expected: 0.005 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 10.582 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 473          |\n",
      "| EpRewMean               | 38.1         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 17           |\n",
      "| TimeElapsed             | 9.77e+03     |\n",
      "| TimestepsSoFar          | 8192         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.2140352    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.009872675  |\n",
      "| optimgain               | 0.0053195544 |\n",
      "| surrgain                | 0.0053195544 |\n",
      "------------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=8192, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "\u001b[35mdone in 175.300 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.648 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00759          0\n",
      "         1   0.000306     0.0136\n",
      "         2   8.49e-07      0.014\n",
      "         3   5.41e-15      0.014\n",
      "\u001b[35mdone in 2.178 seconds\u001b[0m\n",
      "Expected: 0.005 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 9.845 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 493         |\n",
      "| EpRewMean               | 39.2        |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 18          |\n",
      "| TimeElapsed             | 9.96e+03    |\n",
      "| TimestepsSoFar          | 9216        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.2018267   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009848788 |\n",
      "| optimgain               | 0.004813858 |\n",
      "| surrgain                | 0.004813858 |\n",
      "-----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=32.80 +/- 11.27\n",
      "Episode length: 357.80 +/- 110.47\n",
      "Eval num_timesteps=9216, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "\u001b[35mdone in 160.816 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.153 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0143          0\n",
      "         1   6.67e-05      0.019\n",
      "         2   5.76e-06     0.0191\n",
      "         3   1.03e-14     0.0191\n",
      "\u001b[35mdone in 1.755 seconds\u001b[0m\n",
      "Expected: 0.007 Actual: 0.007\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 9.570 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 487         |\n",
      "| EpRewMean               | 40.1        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 20          |\n",
      "| TimeElapsed             | 1.01e+04    |\n",
      "| TimestepsSoFar          | 10240       |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.2248532   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009917725 |\n",
      "| optimgain               | 0.006697757 |\n",
      "| surrgain                | 0.006697757 |\n",
      "-----------------------------------------\n",
      "Connecting to host 127.0.0.1 at port 55074 ...\n",
      "Client connected to server [OK]\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-aliens-lvl3-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x10fd93f90>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=0, episode_reward=34.80 +/- 10.50\n",
      "Episode length: 374.40 +/- 100.99\n",
      "\u001b[35mdone in 160.616 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.223 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00106          0\n",
      "         1   7.56e-05      0.005\n",
      "         2   2.81e-08    0.00525\n",
      "         3   1.65e-15    0.00525\n",
      "\u001b[35mdone in 1.736 seconds\u001b[0m\n",
      "Expected: 0.002 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 10.347 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 537          |\n",
      "| EpRewMean               | 40           |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 1            |\n",
      "| TimeElapsed             | 177          |\n",
      "| TimestepsSoFar          | 1024         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.2056639    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.009314259  |\n",
      "| optimgain               | 0.0016566829 |\n",
      "| surrgain                | 0.0016566829 |\n",
      "------------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=1024, episode_reward=34.00 +/- 9.98\n",
      "Episode length: 367.40 +/- 99.83\n",
      "\u001b[35mdone in 162.261 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.549 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00273          0\n",
      "         1   0.000153    0.00467\n",
      "         2    1.3e-06    0.00535\n",
      "         3   2.04e-15    0.00537\n",
      "\u001b[35mdone in 3.121 seconds\u001b[0m\n",
      "Expected: 0.002 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 14.907 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 556          |\n",
      "| EpRewMean               | 40           |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 3            |\n",
      "| TimeElapsed             | 363          |\n",
      "| TimestepsSoFar          | 2048         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.134215     |\n",
      "| explained_variance_t... | -1.19e-07    |\n",
      "| meankl                  | 0.009583664  |\n",
      "| optimgain               | 0.0021578143 |\n",
      "| surrgain                | 0.0021578143 |\n",
      "------------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=2048, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "\u001b[35mdone in 170.572 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.562 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0109          0\n",
      "         1    0.00168     0.0133\n",
      "         2   9.12e-06     0.0157\n",
      "         3    9.4e-15     0.0157\n",
      "\u001b[35mdone in 1.760 seconds\u001b[0m\n",
      "Expected: 0.006 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 11.254 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 536          |\n",
      "| EpRewMean               | 37.4         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 5            |\n",
      "| TimeElapsed             | 552          |\n",
      "| TimestepsSoFar          | 3072         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.1149228    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.009339581  |\n",
      "| optimgain               | 0.0050741453 |\n",
      "| surrgain                | 0.0050741453 |\n",
      "------------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=28.40 +/- 12.13\n",
      "Episode length: 306.00 +/- 107.02\n",
      "Eval num_timesteps=3072, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "\u001b[35mdone in 164.617 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.752 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0104          0\n",
      "         1    0.00105     0.0102\n",
      "         2   2.01e-06     0.0127\n",
      "         3   9.49e-15     0.0127\n",
      "\u001b[35mdone in 2.197 seconds\u001b[0m\n",
      "Expected: 0.005 Actual: 0.004\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 11.870 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 523         |\n",
      "| EpRewMean               | 36.9        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 7           |\n",
      "| TimeElapsed             | 736         |\n",
      "| TimestepsSoFar          | 4096        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.0311986   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009306114 |\n",
      "| optimgain               | 0.004386322 |\n",
      "| surrgain                | 0.004386322 |\n",
      "-----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=39.80 +/- 4.40\n",
      "Episode length: 422.20 +/- 51.60\n",
      "Eval num_timesteps=4096, episode_reward=37.80 +/- 8.40\n",
      "Episode length: 406.40 +/- 83.20\n",
      "\u001b[35mdone in 160.273 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.682 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0321          0\n",
      "         1    0.00168     0.0161\n",
      "         2   9.94e-06     0.0214\n",
      "         3   2.17e-14     0.0215\n",
      "\u001b[35mdone in 1.966 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 11.479 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 560          |\n",
      "| EpRewMean               | 37.2         |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 8            |\n",
      "| TimeElapsed             | 915          |\n",
      "| TimestepsSoFar          | 5120         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 0.94344896   |\n",
      "| explained_variance_t... | 1.19e-07     |\n",
      "| meankl                  | 0.009492862  |\n",
      "| optimgain               | 0.0075358357 |\n",
      "| surrgain                | 0.0075358357 |\n",
      "------------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=29.20 +/- 15.79\n",
      "Episode length: 329.00 +/- 146.50\n",
      "Eval num_timesteps=5120, episode_reward=36.20 +/- 11.60\n",
      "Episode length: 393.20 +/- 109.60\n",
      "\u001b[35mdone in 150.098 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.319 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0105          0\n",
      "         1   0.000283     0.0313\n",
      "         2   9.41e-07     0.0322\n",
      "         3   7.64e-15     0.0322\n",
      "\u001b[35mdone in 1.832 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 11.079 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 510         |\n",
      "| EpRewMean               | 31.2        |\n",
      "| EpThisIter              | 3           |\n",
      "| EpisodesSoFar           | 11          |\n",
      "| TimeElapsed             | 1.08e+03    |\n",
      "| TimestepsSoFar          | 6144        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 0.9389328   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009930241 |\n",
      "| optimgain               | 0.008042663 |\n",
      "| surrgain                | 0.008042663 |\n",
      "-----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=36.40 +/- 8.91\n",
      "Episode length: 386.80 +/- 87.70\n",
      "Eval num_timesteps=6144, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "\u001b[35mdone in 160.552 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.200 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00934          0\n",
      "         1   0.000909    0.00955\n",
      "         2   1.26e-07     0.0178\n",
      "         3   6.96e-15     0.0178\n",
      "\u001b[35mdone in 1.795 seconds\u001b[0m\n",
      "Expected: 0.005 Actual: 0.006\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 10.899 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 503          |\n",
      "| EpRewMean               | 30.1         |\n",
      "| EpThisIter              | 3            |\n",
      "| EpisodesSoFar           | 14           |\n",
      "| TimeElapsed             | 1.26e+03     |\n",
      "| TimestepsSoFar          | 7168         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.0535333    |\n",
      "| explained_variance_t... | 1.19e-07     |\n",
      "| meankl                  | 0.011116137  |\n",
      "| optimgain               | 0.0059915897 |\n",
      "| surrgain                | 0.0059915897 |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=7168, episode_reward=32.40 +/- 14.35\n",
      "Episode length: 351.60 +/- 137.36\n",
      "\u001b[35mdone in 160.847 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.176 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0559          0\n",
      "         1     0.0011     0.0204\n",
      "         2   2.85e-05     0.0223\n",
      "         3   4.07e-14     0.0224\n",
      "\u001b[35mdone in 1.806 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 10.618 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 466         |\n",
      "| EpRewMean               | 28.7        |\n",
      "| EpThisIter              | 3           |\n",
      "| EpisodesSoFar           | 17          |\n",
      "| TimeElapsed             | 1.44e+03    |\n",
      "| TimestepsSoFar          | 8192        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 0.94646645  |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.009584226 |\n",
      "| optimgain               | 0.009401166 |\n",
      "| surrgain                | 0.009401166 |\n",
      "-----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=36.60 +/- 10.80\n",
      "Episode length: 396.80 +/- 102.40\n",
      "Eval num_timesteps=8192, episode_reward=29.60 +/- 16.01\n",
      "Episode length: 329.00 +/- 152.60\n",
      "\u001b[35mdone in 143.259 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.365 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00332          0\n",
      "         1    0.00153     0.0118\n",
      "         2   4.89e-05     0.0167\n",
      "         3   6.01e-15     0.0171\n",
      "\u001b[35mdone in 1.758 seconds\u001b[0m\n",
      "Expected: 0.004 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 10.355 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 480          |\n",
      "| EpRewMean               | 29.7         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 19           |\n",
      "| TimeElapsed             | 1.6e+03      |\n",
      "| TimestepsSoFar          | 9216         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 0.8911112    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.008702824  |\n",
      "| optimgain               | 0.0034782507 |\n",
      "| surrgain                | 0.0034782507 |\n",
      "------------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=42.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "Eval num_timesteps=9216, episode_reward=41.00 +/- 2.00\n",
      "Episode length: 431.80 +/- 32.40\n",
      "\u001b[35mdone in 173.485 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.178 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0    0.00303          0\n",
      "         1   0.000591     0.0063\n",
      "         2   0.000116     0.0127\n",
      "         3   2.88e-15     0.0143\n",
      "\u001b[35mdone in 1.837 seconds\u001b[0m\n",
      "Expected: 0.003 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 10.765 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 458          |\n",
      "| EpRewMean               | 28.4         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 21           |\n",
      "| TimeElapsed             | 1.79e+03     |\n",
      "| TimestepsSoFar          | 10240        |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 0.92291856   |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.009961847  |\n",
      "| optimgain               | 0.0033734466 |\n",
      "| surrgain                | 0.0033734466 |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import gym_gvgai\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import ActorCriticPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import SAC\n",
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import TRPO\n",
    "\n",
    "\n",
    "def show_state(env, step=0, name=\"\", info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name,step,info))\n",
    "    plt.axis('off')\n",
    "              \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    \n",
    "env = gym.make('gvgai-aliens-lvl0-v0')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "    \n",
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "log_path='./logs/', eval_freq=500,\n",
    "deterministic=True, render=False)\n",
    "\n",
    "\n",
    "model = TRPO(MlpPolicy, env, verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_aliens\")\n",
    "\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-aliens-lvl1-v0')\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_aliens\")\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-aliens-lvl2-v0')\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_aliens\")\n",
    "\n",
    "\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-aliens-lvl3-v0')\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_aliens\")\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
