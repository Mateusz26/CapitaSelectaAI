{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host 127.0.0.1 at port 58302 ...\n",
      "Client connected to server [OK]\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1396f0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1396f0750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1396f0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1396f0750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14e2e2d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14e2e2d50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14e2e2d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14e2e2d50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/trpo_mpi/trpo_mpi.py:192: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/trpo_mpi/trpo_mpi.py:266: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-zelda-lvl0-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x1396d69d0>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 448.00 +/- 454.91\n",
      "New best mean reward!\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 484.00 +/- 416.89\n",
      "\u001b[35mdone in 164.176 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.918 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.137          0\n",
      "         1      0.147     0.0178\n",
      "         2     0.0618     0.0512\n",
      "         3     0.0134      0.065\n",
      "         4     0.0171     0.0735\n",
      "         5     0.0616      0.148\n",
      "         6      0.147      0.274\n",
      "         7      0.129      0.812\n",
      "         8      0.188      0.966\n",
      "         9     0.0113       1.05\n",
      "        10    0.00879       1.11\n",
      "\u001b[35mdone in 2.197 seconds\u001b[0m\n",
      "Expected: 0.045 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 2.755 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 278          |\n",
      "| EpRewMean               | -1           |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 2            |\n",
      "| TimeElapsed             | 171          |\n",
      "| TimestepsSoFar          | 1024         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7873958    |\n",
      "| explained_variance_t... | -0.202       |\n",
      "| meankl                  | 0.004674707  |\n",
      "| optimgain               | 0.0049656387 |\n",
      "| surrgain                | 0.0049656387 |\n",
      "------------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 404.00 +/- 351.97\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 300.00 +/- 119.73\n",
      "\u001b[35mdone in 133.281 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.797 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        110          0\n",
      "         1       7.24    0.00048\n",
      "         2      0.249   0.000509\n",
      "         3       5.73     0.0302\n",
      "         4      0.378     0.0319\n",
      "         5      0.697      0.032\n",
      "         6        133     0.0492\n",
      "         7       1.96      0.311\n",
      "         8        363      0.343\n",
      "         9       29.8      0.654\n",
      "        10       3.04      0.666\n",
      "\u001b[35mdone in 2.078 seconds\u001b[0m\n",
      "Expected: 0.069 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.000 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 389          |\n",
      "| EpRewMean               | -0.5         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 4            |\n",
      "| TimeElapsed             | 311          |\n",
      "| TimestepsSoFar          | 2048         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7797172    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.007084885  |\n",
      "| optimgain               | 0.0046483492 |\n",
      "| surrgain                | 0.0046483492 |\n",
      "------------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 403.20 +/- 235.65\n",
      "Eval num_timesteps=2048, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 847.20 +/- 686.28\n",
      "New best mean reward!\n",
      "\u001b[35mdone in 209.534 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.177 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0         26          0\n",
      "         1       0.05   0.000245\n",
      "         2     0.0772     0.0402\n",
      "         3     0.0784     0.0402\n",
      "         4     0.0344     0.0648\n",
      "         5       28.3     0.0735\n",
      "         6      0.617       1.18\n",
      "         7        837       3.88\n",
      "         8      0.086       4.29\n",
      "         9       3.99       4.41\n",
      "        10    0.00284       4.41\n",
      "\u001b[35mdone in 2.922 seconds\u001b[0m\n",
      "Expected: 0.102 Actual: 0.001\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.285 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 426          |\n",
      "| EpRewMean               | 0            |\n",
      "| EpThisIter              | 3            |\n",
      "| EpisodesSoFar           | 7            |\n",
      "| TimeElapsed             | 530          |\n",
      "| TimestepsSoFar          | 3072         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7841728    |\n",
      "| explained_variance_t... | 5.96e-08     |\n",
      "| meankl                  | 0.005691653  |\n",
      "| optimgain               | 0.0009895223 |\n",
      "| surrgain                | 0.0009895223 |\n",
      "------------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 506.40 +/- 441.04\n",
      "Eval num_timesteps=3072, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 566.40 +/- 743.05\n",
      "\u001b[35mdone in 185.320 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.792 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       3.86          0\n",
      "         1     0.0382   0.000211\n",
      "         2      0.183     0.0626\n",
      "         3     0.0337     0.0627\n",
      "         4      0.988      0.608\n",
      "         5      0.453      0.609\n",
      "         6       1.17       3.12\n",
      "         7       1.31       3.12\n",
      "         8       1.08       8.43\n",
      "         9       1.46       8.43\n",
      "        10     0.0726       9.48\n",
      "\u001b[35mdone in 2.058 seconds\u001b[0m\n",
      "Expected: 0.154 Actual: -0.000\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.154 Actual: 0.000\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 2.975 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 353           |\n",
      "| EpRewMean               | -0.182        |\n",
      "| EpThisIter              | 4             |\n",
      "| EpisodesSoFar           | 11            |\n",
      "| TimeElapsed             | 723           |\n",
      "| TimestepsSoFar          | 4096          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.7855381     |\n",
      "| explained_variance_t... | -1.19e-07     |\n",
      "| meankl                  | 0.0013978323  |\n",
      "| optimgain               | 0.00011352217 |\n",
      "| surrgain                | 0.00011352217 |\n",
      "-------------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 244.80 +/- 130.63\n",
      "Eval num_timesteps=4096, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 791.20 +/- 678.59\n",
      "\u001b[35mdone in 187.457 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.775 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0458          0\n",
      "         1     0.0743   0.000125\n",
      "         2    0.00035     0.0274\n",
      "         3      0.028     0.0275\n",
      "         4   2.75e-05      0.028\n",
      "         5      0.133     0.0352\n",
      "         6   0.000596     0.0408\n",
      "         7   0.000134      0.106\n",
      "         8   1.03e-05      0.106\n",
      "         9   2.59e-07      0.106\n",
      "        10   9.94e-07      0.106\n",
      "\u001b[35mdone in 2.037 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.010\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 2.971 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 362         |\n",
      "| EpRewMean               | -0.154      |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 13          |\n",
      "| TimeElapsed             | 917         |\n",
      "| TimestepsSoFar          | 5120        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7677529   |\n",
      "| explained_variance_t... | 1.19e-07    |\n",
      "| meankl                  | 0.009648572 |\n",
      "| optimgain               | 0.009975836 |\n",
      "| surrgain                | 0.009975836 |\n",
      "-----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 433.60 +/- 290.83\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 212.80 +/- 123.48\n",
      "\u001b[35mdone in 134.037 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.754 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0141          0\n",
      "         1     0.0016     0.0132\n",
      "         2   0.000149     0.0155\n",
      "         3   0.000115     0.0164\n",
      "         4    0.00248     0.0758\n",
      "         5    0.00226      0.468\n",
      "         6   2.38e-05      0.528\n",
      "         7   6.04e-05       0.53\n",
      "         8   0.000371      0.535\n",
      "         9   1.16e-06      0.674\n",
      "        10   5.69e-07      0.674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mdone in 2.129 seconds\u001b[0m\n",
      "Expected: 0.012 Actual: 0.000\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.099 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 369           |\n",
      "| EpRewMean               | -0.188        |\n",
      "| EpThisIter              | 3             |\n",
      "| EpisodesSoFar           | 16            |\n",
      "| TimeElapsed             | 1.06e+03      |\n",
      "| TimestepsSoFar          | 6144          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.763126      |\n",
      "| explained_variance_t... | -1.19e-07     |\n",
      "| meankl                  | 0.005862917   |\n",
      "| optimgain               | 3.4381286e-05 |\n",
      "| surrgain                | 3.4381286e-05 |\n",
      "-------------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 401.60 +/- 361.44\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 229.60 +/- 87.14\n",
      "\u001b[35mdone in 132.404 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.768 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0283          0\n",
      "         1    0.00131     0.0225\n",
      "         2   2.18e-05     0.0244\n",
      "         3   6.17e-06     0.0245\n",
      "         4   1.13e-06     0.0247\n",
      "         5   3.43e-09     0.0247\n",
      "         6   4.85e-13     0.0247\n",
      "\u001b[35mdone in 1.299 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 2.992 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 398         |\n",
      "| EpRewMean               | 0.0556      |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 18          |\n",
      "| TimeElapsed             | 1.2e+03     |\n",
      "| TimestepsSoFar          | 7168        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7748148   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.00906503  |\n",
      "| optimgain               | 0.008514537 |\n",
      "| surrgain                | 0.008514537 |\n",
      "-----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 305.60 +/- 262.63\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 422.40 +/- 385.84\n",
      "\u001b[35mdone in 145.239 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.752 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0237          0\n",
      "         1   0.000228     0.0228\n",
      "         2   8.62e-06     0.0232\n",
      "         3   8.16e-08     0.0232\n",
      "         4   1.85e-11     0.0232\n",
      "\u001b[35mdone in 0.848 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.007 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 389         |\n",
      "| EpRewMean               | 0           |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 19          |\n",
      "| TimeElapsed             | 1.35e+03    |\n",
      "| TimestepsSoFar          | 8192        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.742374    |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010282048 |\n",
      "| optimgain               | 0.008769693 |\n",
      "| surrgain                | 0.008769693 |\n",
      "-----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 734.40 +/- 478.33\n",
      "Eval num_timesteps=8192, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 93.60 +/- 50.57\n",
      "\u001b[35mdone in 162.904 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.209 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0183          0\n",
      "         1    0.00216     0.0213\n",
      "         2   3.82e-05     0.0251\n",
      "         3   3.64e-08     0.0253\n",
      "         4   7.03e-10     0.0253\n",
      "         5   1.35e-14     0.0253\n",
      "\u001b[35mdone in 1.469 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.161 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 382         |\n",
      "| EpRewMean               | 0.208       |\n",
      "| EpThisIter              | 5           |\n",
      "| EpisodesSoFar           | 24          |\n",
      "| TimeElapsed             | 1.52e+03    |\n",
      "| TimestepsSoFar          | 9216        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7330321   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009891877 |\n",
      "| optimgain               | 0.007947423 |\n",
      "| surrgain                | 0.007947423 |\n",
      "-----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 451.20 +/- 319.93\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 424.00 +/- 277.07\n",
      "\u001b[35mdone in 169.777 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.768 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0305          0\n",
      "         1     0.0016      0.025\n",
      "         2   2.82e-05     0.0272\n",
      "         3   4.81e-07     0.0273\n",
      "         4   2.12e-09     0.0273\n",
      "         5   2.14e-14     0.0273\n",
      "\u001b[35mdone in 1.127 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.010\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.113 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 342         |\n",
      "| EpRewMean               | 0.103       |\n",
      "| EpThisIter              | 5           |\n",
      "| EpisodesSoFar           | 29          |\n",
      "| TimeElapsed             | 1.69e+03    |\n",
      "| TimestepsSoFar          | 10240       |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7197732   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010128304 |\n",
      "| optimgain               | 0.00983944  |\n",
      "| surrgain                | 0.00983944  |\n",
      "-----------------------------------------\n",
      "Connecting to host 127.0.0.1 at port 54454 ...\n",
      "Client connected to server [OK]\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-zelda-lvl1-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x1396d69d0>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 400.00 +/- 286.74\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 512.00 +/- 202.59\n",
      "\u001b[35mdone in 163.346 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.743 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0941          0\n",
      "         1       1.08    0.00235\n",
      "         2     0.0137     0.0631\n",
      "         3      0.446     0.0881\n",
      "         4       0.01       0.09\n",
      "         5     0.0194      0.145\n",
      "         6      0.184      0.147\n",
      "         7      0.015      0.228\n",
      "         8      0.815      0.312\n",
      "         9    0.00812       0.32\n",
      "        10     0.0293      0.491\n",
      "\u001b[35mdone in 2.069 seconds\u001b[0m\n",
      "Expected: 0.032 Actual: 0.010\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.105 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 229         |\n",
      "| EpRewMean               | -1          |\n",
      "| EpThisIter              | 4           |\n",
      "| EpisodesSoFar           | 4           |\n",
      "| TimeElapsed             | 170         |\n",
      "| TimestepsSoFar          | 1024        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7107756   |\n",
      "| explained_variance_t... | 2.74e-06    |\n",
      "| meankl                  | 0.003859567 |\n",
      "| optimgain               | 0.010295051 |\n",
      "| surrgain                | 0.010295051 |\n",
      "-----------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 265.60 +/- 140.73\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 592.80 +/- 485.87\n",
      "\u001b[35mdone in 153.942 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.769 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0324          0\n",
      "         1      0.199    0.00136\n",
      "         2    0.00684     0.0333\n",
      "         3    0.00444     0.0426\n",
      "         4     0.0013     0.0426\n",
      "         5     0.0021     0.0501\n",
      "         6      0.383      0.113\n",
      "         7    0.00527      0.132\n",
      "         8   0.000132      0.231\n",
      "         9   3.22e-05      0.231\n",
      "        10   0.000168      0.233\n",
      "\u001b[35mdone in 2.086 seconds\u001b[0m\n",
      "Expected: 0.016 Actual: 0.010\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.137 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 395         |\n",
      "| EpRewMean               | -0.2        |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 5           |\n",
      "| TimeElapsed             | 331         |\n",
      "| TimestepsSoFar          | 2048        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.734187    |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009655459 |\n",
      "| optimgain               | 0.010252211 |\n",
      "| surrgain                | 0.010252211 |\n",
      "-----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=-0.40 +/- 0.80\n",
      "Episode length: 762.80 +/- 759.06\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2048, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 434.00 +/- 645.78\n",
      "\u001b[35mdone in 218.704 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.542 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        111          0\n",
      "         1      0.575   0.000354\n",
      "         2       66.3       1.67\n",
      "         3       8.66       1.68\n",
      "         4        213       13.9\n",
      "         5       6.14       13.9\n",
      "         6         71       16.5\n",
      "         7       2.56       16.5\n",
      "         8        560         31\n",
      "         9       33.8         31\n",
      "        10        265       57.2\n",
      "\u001b[35mdone in 2.052 seconds\u001b[0m\n",
      "Expected: 0.883 Actual: -0.007\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.883 Actual: -0.008\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.883 Actual: -0.008\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.883 Actual: -0.002\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.883 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.883 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.883 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.883 Actual: 0.000\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.005 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 395           |\n",
      "| EpRewMean               | -0.2          |\n",
      "| EpThisIter              | 0             |\n",
      "| EpisodesSoFar           | 5             |\n",
      "| TimeElapsed             | 564           |\n",
      "| TimestepsSoFar          | 3072          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.7350297     |\n",
      "| explained_variance_t... | 0             |\n",
      "| meankl                  | 0.00025701686 |\n",
      "| optimgain               | 9.023014e-05  |\n",
      "| surrgain                | 9.023014e-05  |\n",
      "-------------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 333.20 +/- 356.84\n",
      "Eval num_timesteps=3072, episode_reward=0.20 +/- 0.40\n",
      "Episode length: 1328.00 +/- 356.64\n",
      "New best mean reward!\n",
      "\u001b[35mdone in 291.212 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.795 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0863          0\n",
      "         1      0.166    0.00364\n",
      "         2     0.0014     0.0372\n",
      "         3    4.8e-05     0.0385\n",
      "         4   0.000231     0.0386\n",
      "         5   2.05e-05     0.0386\n",
      "         6    7.9e-05     0.0391\n",
      "         7    0.00158      0.155\n",
      "         8    0.00258       0.16\n",
      "         9   2.81e-08      0.271\n",
      "        10    6.7e-07      0.271\n",
      "\u001b[35mdone in 2.186 seconds\u001b[0m\n",
      "Expected: 0.014 Actual: 0.013\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.320 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 662         |\n",
      "| EpRewMean               | 0.833       |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 6           |\n",
      "| TimeElapsed             | 862         |\n",
      "| TimestepsSoFar          | 4096        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.703156    |\n",
      "| explained_variance_t... | 1.19e-07    |\n",
      "| meankl                  | 0.010414427 |\n",
      "| optimgain               | 0.012829233 |\n",
      "| surrgain                | 0.012829233 |\n",
      "-----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 374.40 +/- 186.87\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 108.00 +/- 24.40\n",
      "\u001b[35mdone in 99.616 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.885 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       1.85          0\n",
      "         1      0.889   5.17e-06\n",
      "         2       1.39    0.00747\n",
      "         3        234     0.0083\n",
      "         4       1.13     0.0345\n",
      "         5   2.03e+03     0.0429\n",
      "         6       5.62       1.32\n",
      "         7        114       1.32\n",
      "         8        101       5.55\n",
      "         9        223       5.55\n",
      "        10        145       6.61\n",
      "\u001b[35mdone in 2.310 seconds\u001b[0m\n",
      "Expected: 0.268 Actual: 0.003\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.268 Actual: 0.006\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.268 Actual: 0.004\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.268 Actual: 0.000\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.304 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 478           |\n",
      "| EpRewMean               | 0.1           |\n",
      "| EpThisIter              | 4             |\n",
      "| EpisodesSoFar           | 10            |\n",
      "| TimeElapsed             | 971           |\n",
      "| TimestepsSoFar          | 5120          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.6241143     |\n",
      "| explained_variance_t... | -1.19e-07     |\n",
      "| meankl                  | 0.009751646   |\n",
      "| optimgain               | 0.00048144162 |\n",
      "| surrgain                | 0.00048144162 |\n",
      "-------------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 294.40 +/- 165.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 411.20 +/- 150.87\n",
      "\u001b[35mdone in 131.237 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.840 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        276          0\n",
      "         1       1.85   2.53e-05\n",
      "         2       3.56    0.00823\n",
      "         3       12.4    0.00825\n",
      "         4       26.3      0.265\n",
      "         5       80.4      0.266\n",
      "         6       9.94      0.364\n",
      "         7   3.05e+04      0.573\n",
      "         8       59.7      0.632\n",
      "         9   2.23e+06       12.6\n",
      "        10        511       17.5\n",
      "\u001b[35mdone in 3.029 seconds\u001b[0m\n",
      "Expected: 0.583 Actual: 0.000\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.583 Actual: -0.004\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.583 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.583 Actual: -0.002\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.583 Actual: -0.003\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.583 Actual: -0.002\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.583 Actual: 0.001\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.296 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 515           |\n",
      "| EpRewMean               | 0             |\n",
      "| EpThisIter              | 1             |\n",
      "| EpisodesSoFar           | 11            |\n",
      "| TimeElapsed             | 1.12e+03      |\n",
      "| TimestepsSoFar          | 6144          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.625326      |\n",
      "| explained_variance_t... | -1.19e-07     |\n",
      "| meankl                  | 0.00015830732 |\n",
      "| optimgain               | 0.0011505189  |\n",
      "| surrgain                | 0.0011505189  |\n",
      "-------------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 181.60 +/- 54.18\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 638.40 +/- 458.84\n",
      "\u001b[35mdone in 148.376 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.862 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       1.04          0\n",
      "         1      0.133   3.46e-06\n",
      "         2      0.237    0.00703\n",
      "         3         29     0.0073\n",
      "         4      0.312     0.0134\n",
      "         5       25.9     0.0449\n",
      "         6      0.242     0.0453\n",
      "         7      0.469     0.0871\n",
      "         8       14.4     0.0873\n",
      "         9      0.358      0.182\n",
      "        10        120      0.184\n",
      "\u001b[35mdone in 2.440 seconds\u001b[0m\n",
      "Expected: 0.030 Actual: -0.004\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.030 Actual: -0.000\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.030 Actual: -0.000\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.030 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.447 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 506           |\n",
      "| EpRewMean               | -0.214        |\n",
      "| EpThisIter              | 3             |\n",
      "| EpisodesSoFar           | 14            |\n",
      "| TimeElapsed             | 1.28e+03      |\n",
      "| TimestepsSoFar          | 7168          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.6589513     |\n",
      "| explained_variance_t... | 0             |\n",
      "| meankl                  | 0.00069820054 |\n",
      "| optimgain               | 0.0015286864  |\n",
      "| surrgain                | 0.0015286864  |\n",
      "-------------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 444.80 +/- 424.85\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 161.60 +/- 99.30\n",
      "\u001b[35mdone in 116.853 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.918 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        308          0\n",
      "         1       1.45    0.00116\n",
      "         2       7.77       0.17\n",
      "         3       13.5      0.172\n",
      "         4       16.6       2.76\n",
      "         5        345       2.78\n",
      "         6         74       14.6\n",
      "         7   2.06e+04         16\n",
      "         8         32       40.4\n",
      "         9    3.2e+04       43.1\n",
      "        10       17.4       51.9\n",
      "\u001b[35mdone in 2.476 seconds\u001b[0m\n",
      "Expected: 1.030 Actual: 0.007\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 1.030 Actual: 0.008\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 1.030 Actual: 0.008\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 1.030 Actual: 0.006\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 1.030 Actual: 0.004\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.649 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 482          |\n",
      "| EpRewMean               | -0.312       |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 16           |\n",
      "| TimeElapsed             | 1.4e+03      |\n",
      "| TimestepsSoFar          | 8192         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.659403     |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.011761412  |\n",
      "| optimgain               | 0.0041136486 |\n",
      "| surrgain                | 0.0041136486 |\n",
      "------------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 489.60 +/- 492.41\n",
      "Eval num_timesteps=8192, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 300.00 +/- 230.07\n",
      "\u001b[35mdone in 146.190 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.857 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        144          0\n",
      "         1      0.737   7.24e-05\n",
      "         2       47.7     0.0632\n",
      "         3      0.595     0.0636\n",
      "         4        505      0.516\n",
      "         5       1.45      0.521\n",
      "         6        251       1.18\n",
      "         7      0.617       1.19\n",
      "         8   1.37e+04       2.54\n",
      "         9        4.4       2.75\n",
      "        10   2.51e+04       10.8\n",
      "\u001b[35mdone in 2.313 seconds\u001b[0m\n",
      "Expected: 0.311 Actual: -0.002\n",
      "violated KL constraint. shrinking step.\n",
      "Expected: 0.311 Actual: -0.002\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.311 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.311 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.457 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 483          |\n",
      "| EpRewMean               | -0.421       |\n",
      "| EpThisIter              | 3            |\n",
      "| EpisodesSoFar           | 19           |\n",
      "| TimeElapsed             | 1.56e+03     |\n",
      "| TimestepsSoFar          | 9216         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.69624      |\n",
      "| explained_variance_t... | 1.19e-07     |\n",
      "| meankl                  | 0.009105878  |\n",
      "| optimgain               | 0.0024093112 |\n",
      "| surrgain                | 0.0024093112 |\n",
      "------------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 415.20 +/- 436.75\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 276.80 +/- 198.25\n",
      "\u001b[35mdone in 129.173 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.859 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       1.15          0\n",
      "         1     0.0434   0.000588\n",
      "         2    0.00659     0.0314\n",
      "         3     0.0783     0.0401\n",
      "         4    0.00142     0.0405\n",
      "         5    0.00414     0.0499\n",
      "         6      0.131     0.0513\n",
      "         7     0.0184      0.187\n",
      "         8       15.1      0.727\n",
      "         9    0.00649       1.28\n",
      "        10      0.236       1.35\n",
      "\u001b[35mdone in 2.377 seconds\u001b[0m\n",
      "Expected: 0.031 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.545 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 456         |\n",
      "| EpRewMean               | -0.409      |\n",
      "| EpThisIter              | 3           |\n",
      "| EpisodesSoFar           | 22          |\n",
      "| TimeElapsed             | 1.7e+03     |\n",
      "| TimestepsSoFar          | 10240       |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7065322   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009188285 |\n",
      "| optimgain               | 0.007989346 |\n",
      "| surrgain                | 0.007989346 |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host 127.0.0.1 at port 54573 ...\n",
      "Client connected to server [OK]\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-zelda-lvl2-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x1396d69d0>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 183.20 +/- 145.20\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 595.20 +/- 509.89\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 646.40 +/- 610.73\n",
      "\u001b[35mdone in 237.934 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.798 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0776          0\n",
      "         1    0.00615     0.0426\n",
      "         2    0.00012     0.0465\n",
      "         3   1.74e-05     0.0466\n",
      "         4    2.6e-08     0.0466\n",
      "         5    7.5e-14     0.0466\n",
      "\u001b[35mdone in 1.072 seconds\u001b[0m\n",
      "Expected: 0.016 Actual: 0.015\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.161 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 197         |\n",
      "| EpRewMean               | -1          |\n",
      "| EpThisIter              | 3           |\n",
      "| EpisodesSoFar           | 3           |\n",
      "| TimeElapsed             | 244         |\n",
      "| TimestepsSoFar          | 1024        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7060055   |\n",
      "| explained_variance_t... | 0.00248     |\n",
      "| meankl                  | 0.009453733 |\n",
      "| optimgain               | 0.014678705 |\n",
      "| surrgain                | 0.014678705 |\n",
      "-----------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 391.20 +/- 432.24\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 359.20 +/- 178.89\n",
      "\u001b[35mdone in 138.089 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.173 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.021          0\n",
      "         1    0.00107     0.0255\n",
      "         2   2.04e-05     0.0265\n",
      "         3   1.55e-06     0.0266\n",
      "         4   4.56e-08     0.0266\n",
      "         5   1.52e-14     0.0266\n",
      "\u001b[35mdone in 1.526 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.403 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 494         |\n",
      "| EpRewMean               | -1          |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 4           |\n",
      "| TimeElapsed             | 390         |\n",
      "| TimestepsSoFar          | 2048        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7073703   |\n",
      "| explained_variance_t... | 5.96e-08    |\n",
      "| meankl                  | 0.010136971 |\n",
      "| optimgain               | 0.008957811 |\n",
      "| surrgain                | 0.008957811 |\n",
      "-----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 443.20 +/- 323.85\n",
      "Eval num_timesteps=2048, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 876.80 +/- 686.15\n",
      "\u001b[35mdone in 218.952 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.917 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0279          0\n",
      "         1    0.00178     0.0193\n",
      "         2   7.71e-05     0.0221\n",
      "         3   7.52e-06     0.0223\n",
      "         4   1.35e-08     0.0224\n",
      "         5   1.75e-14     0.0224\n",
      "\u001b[35mdone in 1.150 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.350 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 494         |\n",
      "| EpRewMean               | -1          |\n",
      "| EpThisIter              | 0           |\n",
      "| EpisodesSoFar           | 4           |\n",
      "| TimeElapsed             | 616         |\n",
      "| TimestepsSoFar          | 3072        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7515401   |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.010004055 |\n",
      "| optimgain               | 0.008418033 |\n",
      "| surrgain                | 0.008418033 |\n",
      "-----------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 524.00 +/- 385.22\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 900.00 +/- 512.73\n",
      "\u001b[35mdone in 234.757 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.803 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0663          0\n",
      "         1   0.000859     0.0275\n",
      "         2   1.46e-05     0.0287\n",
      "         3   1.26e-07     0.0287\n",
      "         4   1.05e-11     0.0287\n",
      "\u001b[35mdone in 0.940 seconds\u001b[0m\n",
      "Expected: 0.012 Actual: 0.012\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.269 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 756         |\n",
      "| EpRewMean               | -0.2        |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 5           |\n",
      "| TimeElapsed             | 856         |\n",
      "| TimestepsSoFar          | 4096        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.739735    |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009727362 |\n",
      "| optimgain               | 0.011544921 |\n",
      "| surrgain                | 0.011544921 |\n",
      "-----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 544.80 +/- 411.64\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 252.80 +/- 68.32\n",
      "\u001b[35mdone in 142.978 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.804 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.094          0\n",
      "         1    0.00756     0.0418\n",
      "         2   0.000366     0.0479\n",
      "         3      1e-05     0.0483\n",
      "         4    8.6e-07     0.0483\n",
      "         5   5.35e-05     0.0502\n",
      "         6   2.57e-13      0.101\n",
      "\u001b[35mdone in 1.261 seconds\u001b[0m\n",
      "Expected: 0.017 Actual: 0.017\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.640 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 756         |\n",
      "| EpRewMean               | -0.2        |\n",
      "| EpThisIter              | 0           |\n",
      "| EpisodesSoFar           | 5           |\n",
      "| TimeElapsed             | 1.01e+03    |\n",
      "| TimestepsSoFar          | 5120        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7377133   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010131384 |\n",
      "| optimgain               | 0.017149506 |\n",
      "| surrgain                | 0.017149506 |\n",
      "-----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 206.40 +/- 177.10\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 212.00 +/- 79.64\n",
      "\u001b[35mdone in 90.906 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.847 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0405          0\n",
      "         1     0.0057     0.0285\n",
      "         2   0.000271     0.0363\n",
      "         3   1.26e-05     0.0368\n",
      "         4   1.22e-09     0.0369\n",
      "         5   4.97e-14     0.0369\n",
      "\u001b[35mdone in 1.137 seconds\u001b[0m\n",
      "Expected: 0.012 Actual: 0.013\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.539 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 869         |\n",
      "| EpRewMean               | 0.571       |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 7           |\n",
      "| TimeElapsed             | 1.11e+03    |\n",
      "| TimestepsSoFar          | 6144        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7618442   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010480047 |\n",
      "| optimgain               | 0.012568108 |\n",
      "| surrgain                | 0.012568108 |\n",
      "-----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 174.40 +/- 74.00\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 416.80 +/- 289.75\n",
      "\u001b[35mdone in 114.433 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.829 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0341          0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1    0.00202     0.0244\n",
      "         2   1.42e-05     0.0269\n",
      "         3   7.42e-07     0.0269\n",
      "         4   1.48e-08     0.0269\n",
      "         5   3.67e-14     0.0269\n",
      "\u001b[35mdone in 1.129 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 3.540 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 755         |\n",
      "| EpRewMean               | 0.222       |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 9           |\n",
      "| TimeElapsed             | 1.23e+03    |\n",
      "| TimestepsSoFar          | 7168        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.757188    |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009735188 |\n",
      "| optimgain               | 0.009426966 |\n",
      "| surrgain                | 0.009426966 |\n",
      "-----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 594.40 +/- 620.44\n",
      "Eval num_timesteps=7168, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 332.00 +/- 155.91\n",
      "\u001b[35mdone in 164.155 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.976 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0221          0\n",
      "         1   0.000585     0.0177\n",
      "         2   6.68e-06     0.0189\n",
      "         3   4.48e-07     0.0189\n",
      "         4    1.2e-09     0.0189\n",
      "         5   1.08e-13     0.0189\n",
      "\u001b[35mdone in 1.275 seconds\u001b[0m\n",
      "Expected: 0.007 Actual: 0.007\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.190 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 793         |\n",
      "| EpRewMean               | 0.3         |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 10          |\n",
      "| TimeElapsed             | 1.4e+03     |\n",
      "| TimestepsSoFar          | 8192        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7388351   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009783341 |\n",
      "| optimgain               | 0.007177249 |\n",
      "| surrgain                | 0.007177249 |\n",
      "-----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 416.00 +/- 382.62\n",
      "Eval num_timesteps=8192, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 1103.20 +/- 564.65\n",
      "\u001b[35mdone in 246.603 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.792 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0713          0\n",
      "         1   0.000635     0.0486\n",
      "         2   3.08e-05      0.049\n",
      "         3   2.58e-07      0.049\n",
      "         4   1.91e-08      0.049\n",
      "         5   6.99e-14      0.049\n",
      "\u001b[35mdone in 1.101 seconds\u001b[0m\n",
      "Expected: 0.016 Actual: 0.015\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.027 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 733         |\n",
      "| EpRewMean               | 0.0833      |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 12          |\n",
      "| TimeElapsed             | 1.65e+03    |\n",
      "| TimestepsSoFar          | 9216        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7398684   |\n",
      "| explained_variance_t... | 1.19e-07    |\n",
      "| meankl                  | 0.00943334  |\n",
      "| optimgain               | 0.014828019 |\n",
      "| surrgain                | 0.014828019 |\n",
      "-----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 294.40 +/- 274.03\n",
      "Eval num_timesteps=9216, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 292.00 +/- 245.90\n",
      "\u001b[35mdone in 115.448 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.755 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0291          0\n",
      "         1    0.00248     0.0208\n",
      "         2   0.000128     0.0251\n",
      "         3   1.21e-06     0.0254\n",
      "         4   1.51e-08     0.0254\n",
      "         5   5.91e-14     0.0254\n",
      "\u001b[35mdone in 1.056 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.363 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 719         |\n",
      "| EpRewMean               | 0           |\n",
      "| EpThisIter              | 1           |\n",
      "| EpisodesSoFar           | 13          |\n",
      "| TimeElapsed             | 1.77e+03    |\n",
      "| TimestepsSoFar          | 10240       |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7209736   |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.009981201 |\n",
      "| optimgain               | 0.008952383 |\n",
      "| surrgain                | 0.008952383 |\n",
      "-----------------------------------------\n",
      "Connecting to host 127.0.0.1 at port 54902 ...\n",
      "Client connected to server [OK]\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-zelda-lvl3-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x1396d69d0>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 410.40 +/- 215.93\n",
      "Eval num_timesteps=0, episode_reward=-0.80 +/- 0.40\n",
      "Episode length: 774.40 +/- 770.08\n",
      "\u001b[35mdone in 198.856 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.724 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.303          0\n",
      "         1      0.892      0.492\n",
      "         2      0.203      0.973\n",
      "         3     0.0191       1.05\n",
      "         4      0.036       1.08\n",
      "         5      0.214       1.21\n",
      "         6       1.19       3.51\n",
      "         7   9.61e-06       10.6\n",
      "         8    0.00139       10.6\n",
      "         9   0.000101       10.6\n",
      "        10   2.55e-05       10.6\n",
      "\u001b[35mdone in 2.271 seconds\u001b[0m\n",
      "Expected: 0.180 Actual: 0.001\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.060 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 114           |\n",
      "| EpRewMean               | -0.75         |\n",
      "| EpThisIter              | 8             |\n",
      "| EpisodesSoFar           | 8             |\n",
      "| TimeElapsed             | 209           |\n",
      "| TimestepsSoFar          | 1024          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.7218661     |\n",
      "| explained_variance_t... | 0             |\n",
      "| meankl                  | 5.3021005e-05 |\n",
      "| optimgain               | 0.0007698003  |\n",
      "| surrgain                | 0.0007698003  |\n",
      "-------------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 512.00 +/- 376.72\n",
      "Eval num_timesteps=1024, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 375.20 +/- 85.17\n",
      "\u001b[35mdone in 158.693 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.916 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0338          0\n",
      "         1    0.00307     0.0268\n",
      "         2   7.91e-05     0.0304\n",
      "         3   1.57e-05     0.0306\n",
      "         4   3.05e-07     0.0307\n",
      "         5   2.84e-14     0.0307\n",
      "\u001b[35mdone in 1.030 seconds\u001b[0m\n",
      "Expected: 0.010 Actual: 0.012\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.308 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 105         |\n",
      "| EpRewMean               | -0.789      |\n",
      "| EpThisIter              | 11          |\n",
      "| EpisodesSoFar           | 19          |\n",
      "| TimeElapsed             | 375         |\n",
      "| TimestepsSoFar          | 2048        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7319067   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010822057 |\n",
      "| optimgain               | 0.011706574 |\n",
      "| surrgain                | 0.011706574 |\n",
      "-----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 768.00 +/- 649.74\n",
      "Eval num_timesteps=2048, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 190.40 +/- 164.06\n",
      "\u001b[35mdone in 4441.092 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.078 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0351          0\n",
      "         1    0.00158      0.029\n",
      "         2   2.19e-05     0.0304\n",
      "         3   4.45e-06     0.0305\n",
      "         4   4.63e-08     0.0305\n",
      "         5   2.65e-14     0.0305\n",
      "\u001b[35mdone in 1.252 seconds\u001b[0m\n",
      "Expected: 0.011 Actual: 0.011\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.446 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 95.4        |\n",
      "| EpRewMean               | -0.625      |\n",
      "| EpThisIter              | 13          |\n",
      "| EpisodesSoFar           | 32          |\n",
      "| TimeElapsed             | 4.82e+03    |\n",
      "| TimestepsSoFar          | 3072        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7233853   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.01008793  |\n",
      "| optimgain               | 0.010765508 |\n",
      "| surrgain                | 0.010765508 |\n",
      "-----------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 312.00 +/- 281.98\n",
      "Eval num_timesteps=3072, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 126.40 +/- 81.57\n",
      "\u001b[35mdone in 93.256 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.762 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0238          0\n",
      "         1    0.00182     0.0204\n",
      "         2   8.94e-05     0.0226\n",
      "         3   3.25e-06     0.0228\n",
      "         4   5.04e-09     0.0228\n",
      "         5   2.22e-14     0.0228\n",
      "\u001b[35mdone in 1.071 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.605 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 115         |\n",
      "| EpRewMean               | -0.543      |\n",
      "| EpThisIter              | 3           |\n",
      "| EpisodesSoFar           | 35          |\n",
      "| TimeElapsed             | 4.92e+03    |\n",
      "| TimestepsSoFar          | 4096        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.6874849   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009650351 |\n",
      "| optimgain               | 0.00781163  |\n",
      "| surrgain                | 0.00781163  |\n",
      "-----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 267.20 +/- 144.43\n",
      "Eval num_timesteps=4096, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 553.60 +/- 98.65\n",
      "\u001b[35mdone in 3943.507 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.781 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0232          0\n",
      "         1    0.00177     0.0174\n",
      "         2   0.000107     0.0201\n",
      "         3   1.28e-05     0.0204\n",
      "         4   5.76e-07     0.0205\n",
      "         5   1.97e-14     0.0205\n",
      "\u001b[35mdone in 1.040 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.007\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.919 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 115         |\n",
      "| EpRewMean               | -0.55       |\n",
      "| EpThisIter              | 8           |\n",
      "| EpisodesSoFar           | 43          |\n",
      "| TimeElapsed             | 8.88e+03    |\n",
      "| TimestepsSoFar          | 5120        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.6767389   |\n",
      "| explained_variance_t... | 0.000198    |\n",
      "| meankl                  | 0.009619712 |\n",
      "| optimgain               | 0.007222429 |\n",
      "| surrgain                | 0.007222429 |\n",
      "-----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 219.20 +/- 190.05\n",
      "Eval num_timesteps=5120, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 192.80 +/- 137.74\n",
      "\u001b[35mdone in 91.262 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.733 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0145          0\n",
      "         1    0.00216     0.0155\n",
      "         2   0.000124     0.0189\n",
      "         3   3.21e-05     0.0194\n",
      "         4   3.72e-09     0.0196\n",
      "         5   2.03e-14     0.0196\n",
      "\u001b[35mdone in 1.041 seconds\u001b[0m\n",
      "Expected: 0.007 Actual: 0.007\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.558 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 106         |\n",
      "| EpRewMean               | -0.4        |\n",
      "| EpThisIter              | 14          |\n",
      "| EpisodesSoFar           | 57          |\n",
      "| TimeElapsed             | 8.97e+03    |\n",
      "| TimestepsSoFar          | 6144        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7130123   |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.010610948 |\n",
      "| optimgain               | 0.007247447 |\n",
      "| surrgain                | 0.007247447 |\n",
      "-----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 378.40 +/- 241.02\n",
      "Eval num_timesteps=6144, episode_reward=-1.00 +/- 0.00\n",
      "Episode length: 489.60 +/- 231.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mdone in 154.920 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.886 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0656          0\n",
      "         1    0.00485     0.0266\n",
      "         2   0.000718     0.0336\n",
      "         3   8.71e-05     0.0354\n",
      "         4   8.41e-07     0.0357\n",
      "         5   6.92e-14     0.0357\n",
      "\u001b[35mdone in 1.228 seconds\u001b[0m\n",
      "Expected: 0.013 Actual: 0.013\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.764 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 116         |\n",
      "| EpRewMean               | -0.35       |\n",
      "| EpThisIter              | 7           |\n",
      "| EpisodesSoFar           | 64          |\n",
      "| TimeElapsed             | 9.14e+03    |\n",
      "| TimestepsSoFar          | 7168        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7449192   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010013808 |\n",
      "| optimgain               | 0.012675109 |\n",
      "| surrgain                | 0.012675109 |\n",
      "-----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=0.80 +/- 2.71\n",
      "Episode length: 804.00 +/- 637.88\n",
      "New best mean reward!\n",
      "Eval num_timesteps=7168, episode_reward=3.80 +/- 1.60\n",
      "Episode length: 1858.40 +/- 283.20\n",
      "New best mean reward!\n",
      "\u001b[35mdone in 413.387 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.760 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.039          0\n",
      "         1   0.000815     0.0204\n",
      "         2   8.78e-05     0.0218\n",
      "         3   1.41e-06     0.0221\n",
      "         4   1.85e-08     0.0221\n",
      "         5   4.03e-14     0.0221\n",
      "\u001b[35mdone in 1.088 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.095 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 115         |\n",
      "| EpRewMean               | -0.35       |\n",
      "| EpThisIter              | 5           |\n",
      "| EpisodesSoFar           | 69          |\n",
      "| TimeElapsed             | 9.56e+03    |\n",
      "| TimestepsSoFar          | 8192        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7381551   |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.009957707 |\n",
      "| optimgain               | 0.009123484 |\n",
      "| surrgain                | 0.009123484 |\n",
      "-----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=3.80 +/- 1.60\n",
      "Episode length: 1640.80 +/- 718.40\n",
      "Eval num_timesteps=8192, episode_reward=3.60 +/- 2.24\n",
      "Episode length: 1354.40 +/- 792.56\n",
      "\u001b[35mdone in 465.868 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.948 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0125          0\n",
      "         1    0.00129     0.0182\n",
      "         2   0.000149     0.0214\n",
      "         3    6.9e-06      0.022\n",
      "         4   1.24e-07      0.022\n",
      "         5   1.17e-14      0.022\n",
      "\u001b[35mdone in 1.183 seconds\u001b[0m\n",
      "Expected: 0.007 Actual: 0.007\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.785 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 119          |\n",
      "| EpRewMean               | -0.2         |\n",
      "| EpThisIter              | 8            |\n",
      "| EpisodesSoFar           | 77           |\n",
      "| TimeElapsed             | 1e+04        |\n",
      "| TimestepsSoFar          | 9216         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7118037    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.009804856  |\n",
      "| optimgain               | 0.0065950705 |\n",
      "| surrgain                | 0.0065950705 |\n",
      "------------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=1.60 +/- 2.33\n",
      "Episode length: 1161.60 +/- 742.24\n",
      "Eval num_timesteps=9216, episode_reward=1.60 +/- 1.20\n",
      "Episode length: 1625.60 +/- 397.86\n",
      "\u001b[35mdone in 430.179 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 0.827 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       0.03          0\n",
      "         1    0.00131     0.0207\n",
      "         2   8.86e-05     0.0226\n",
      "         3   5.52e-06     0.0228\n",
      "         4    1.6e-06     0.0228\n",
      "         5   2.09e-14     0.0228\n",
      "\u001b[35mdone in 1.204 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 4.522 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 114         |\n",
      "| EpRewMean               | -0.2        |\n",
      "| EpThisIter              | 6           |\n",
      "| EpisodesSoFar           | 83          |\n",
      "| TimeElapsed             | 1.05e+04    |\n",
      "| TimestepsSoFar          | 10240       |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.6974684   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.010172284 |\n",
      "| optimgain               | 0.008952351 |\n",
      "| surrgain                | 0.008952351 |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import gym_gvgai\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import ActorCriticPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import SAC\n",
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import TRPO\n",
    "\n",
    "\n",
    "def show_state(env, step=0, name=\"\", info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name,step,info))\n",
    "    plt.axis('off')\n",
    "              \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    \n",
    "env = gym.make('gvgai-zelda-lvl0-v0')\n",
    "\n",
    "    \n",
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "log_path='./logs/', eval_freq=500,\n",
    "deterministic=True, render=False)\n",
    "\n",
    "\n",
    "\n",
    "model = TRPO(MlpPolicy, env, verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_zelda\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl1-v0')\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_zelda\")\n",
    "\n",
    "\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl2-v0')\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_zelda\")\n",
    "\n",
    "\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-zelda-lvl3-v0')\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_zelda\")\n",
    "\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
