{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mats/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host 127.0.0.1 at port 49413 ...\n",
      "Client connected to server [OK]\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x146e44f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x146e44f90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x146e44f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x146e44f90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x169e48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x169e48fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x169e48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x169e48fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/trpo_mpi/trpo_mpi.py:192: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/trpo_mpi/trpo_mpi.py:266: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935790>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x155935790>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-boulderdash-lvl2-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x146e0b510>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=0, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 671.392 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.083 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0      0.357          0\n",
      "         1     0.0628    0.00303\n",
      "         2     0.0267    0.00682\n",
      "         3     0.0182     0.0272\n",
      "         4     0.0397     0.0388\n",
      "         5      0.058     0.0448\n",
      "         6     0.0154     0.0507\n",
      "         7      0.177      0.641\n",
      "         8     0.0786      0.694\n",
      "         9      0.234      0.715\n",
      "        10    0.00268      0.899\n",
      "\u001b[35mdone in 4.544 seconds\u001b[0m\n",
      "Expected: 0.037 Actual: 0.005\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.519 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpThisIter              | 0           |\n",
      "| EpisodesSoFar           | 0           |\n",
      "| TimeElapsed             | 687         |\n",
      "| TimestepsSoFar          | 1024        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7895454   |\n",
      "| explained_variance_t... | -0.0316     |\n",
      "| meankl                  | 0.002237881 |\n",
      "| optimgain               | 0.004789401 |\n",
      "| surrgain                | 0.004789401 |\n",
      "-----------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1024, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 659.815 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.846 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       40.1          0\n",
      "         1       7.02   0.000139\n",
      "         2       11.1   0.000206\n",
      "         3       14.1    0.00188\n",
      "         4       1.02    0.00255\n",
      "         5       11.9     0.0044\n",
      "         6       9.09    0.00471\n",
      "         7       2.22    0.00524\n",
      "         8       12.2    0.00567\n",
      "         9      0.126    0.00717\n",
      "        10       6.95    0.00735\n",
      "\u001b[35mdone in 4.199 seconds\u001b[0m\n",
      "Expected: 0.015 Actual: 0.001\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.246 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 1.98e+03     |\n",
      "| EpRewMean               | 7            |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 1            |\n",
      "| TimeElapsed             | 1.36e+03     |\n",
      "| TimestepsSoFar          | 2048         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7894132    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.0003616091 |\n",
      "| optimgain               | 0.0007706622 |\n",
      "| surrgain                | 0.0007706622 |\n",
      "------------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=2048, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 661.435 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.845 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0         68          0\n",
      "         1       33.8   0.000293\n",
      "         2         44   0.000651\n",
      "         3       78.4    0.00156\n",
      "         4      0.594    0.00209\n",
      "         5        7.6    0.00427\n",
      "         6         72     0.0207\n",
      "         7       18.7     0.0228\n",
      "         8       30.4     0.0249\n",
      "         9        352     0.0367\n",
      "        10       2.04      0.117\n",
      "\u001b[35mdone in 4.225 seconds\u001b[0m\n",
      "Expected: 0.043 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.283 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 878          |\n",
      "| EpRewMean               | 2.33         |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 3            |\n",
      "| TimeElapsed             | 2.04e+03     |\n",
      "| TimestepsSoFar          | 3072         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7881398    |\n",
      "| explained_variance_t... | 1.19e-07     |\n",
      "| meankl                  | 0.0028454848 |\n",
      "| optimgain               | 0.0033696047 |\n",
      "| surrgain                | 0.0033696047 |\n",
      "------------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=3072, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 660.891 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.864 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       45.9          0\n",
      "         1       42.9   0.000324\n",
      "         2        2.6    0.00231\n",
      "         3      0.466    0.00235\n",
      "         4       25.4    0.00288\n",
      "         5       5.73     0.0103\n",
      "         6       28.5     0.0116\n",
      "         7       19.4     0.0453\n",
      "         8       33.9      0.122\n",
      "         9       5.51      0.126\n",
      "        10       4.72      0.126\n",
      "\u001b[35mdone in 4.226 seconds\u001b[0m\n",
      "Expected: 0.042 Actual: 0.009\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.290 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 648          |\n",
      "| EpRewMean               | 2.67         |\n",
      "| EpThisIter              | 3            |\n",
      "| EpisodesSoFar           | 6            |\n",
      "| TimeElapsed             | 2.71e+03     |\n",
      "| TimestepsSoFar          | 4096         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.785671     |\n",
      "| explained_variance_t... | -1.19e-07    |\n",
      "| meankl                  | 0.0034947172 |\n",
      "| optimgain               | 0.009027176  |\n",
      "| surrgain                | 0.009027176  |\n",
      "------------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=4096, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 673.096 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.860 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        204          0\n",
      "         1       5.56   0.000243\n",
      "         2       2.09    0.00027\n",
      "         3       44.4    0.00459\n",
      "         4       1.27    0.00758\n",
      "         5      0.568    0.00761\n",
      "         6       21.2     0.0271\n",
      "         7      0.215     0.0281\n",
      "         8       1.86     0.0282\n",
      "         9       50.5     0.0357\n",
      "        10      0.453     0.0549\n",
      "\u001b[35mdone in 4.264 seconds\u001b[0m\n",
      "Expected: 0.027 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.284 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 648          |\n",
      "| EpRewMean               | 2.67         |\n",
      "| EpThisIter              | 0            |\n",
      "| EpisodesSoFar           | 6            |\n",
      "| TimeElapsed             | 3.4e+03      |\n",
      "| TimestepsSoFar          | 5120         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7845157    |\n",
      "| explained_variance_t... | 1.19e-07     |\n",
      "| meankl                  | 0.0013525041 |\n",
      "| optimgain               | 0.0021555908 |\n",
      "| surrgain                | 0.0021555908 |\n",
      "------------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=5120, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 683.522 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.878 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       14.8          0\n",
      "         1        1.8   0.000115\n",
      "         2        4.1   0.000381\n",
      "         3     0.0608     0.0018\n",
      "         4       33.3    0.00464\n",
      "         5      0.441     0.0578\n",
      "         6     0.0526     0.0579\n",
      "         7        100     0.0846\n",
      "         8       1.04      0.113\n",
      "         9       1.68      0.123\n",
      "        10     0.0838      0.124\n",
      "\u001b[35mdone in 4.334 seconds\u001b[0m\n",
      "Expected: 0.024 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.387 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 774          |\n",
      "| EpRewMean               | 3.86         |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 7            |\n",
      "| TimeElapsed             | 4.1e+03      |\n",
      "| TimestepsSoFar          | 6144         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7733333    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.0076144645 |\n",
      "| optimgain               | 0.0077351457 |\n",
      "| surrgain                | 0.0077351457 |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=6144, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 688.492 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.027 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       87.7          0\n",
      "         1       14.7   0.000263\n",
      "         2       2.12   0.000715\n",
      "         3       9.56   0.000889\n",
      "         4       2.76     0.0203\n",
      "         5       4.69     0.0204\n",
      "         6        197      0.231\n",
      "         7        115      0.247\n",
      "         8       30.3      0.262\n",
      "         9        547      0.277\n",
      "        10       6.64       1.27\n",
      "\u001b[35mdone in 5.128 seconds\u001b[0m\n",
      "Expected: 0.152 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 7.458 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 774         |\n",
      "| EpRewMean               | 3.86        |\n",
      "| EpThisIter              | 0           |\n",
      "| EpisodesSoFar           | 7           |\n",
      "| TimeElapsed             | 4.8e+03     |\n",
      "| TimestepsSoFar          | 7168        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7720932   |\n",
      "| explained_variance_t... | -0.00398    |\n",
      "| meankl                  | 0.008203545 |\n",
      "| optimgain               | 0.002661267 |\n",
      "| surrgain                | 0.002661267 |\n",
      "-----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=2.00 +/- 2.00\n",
      "Episode length: 651.60 +/- 784.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=7168, episode_reward=0.00 +/- 1.26\n",
      "Episode length: 437.60 +/- 781.64\n",
      "\u001b[35mdone in 207.505 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.888 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0         93          0\n",
      "         1       8.69   0.000634\n",
      "         2   4.61e+03      0.117\n",
      "         3       90.7       7.14\n",
      "         4        112       7.15\n",
      "         5        160       8.02\n",
      "         6       2.42       8.03\n",
      "         7        653       8.04\n",
      "         8       1.03       8.24\n",
      "         9          1       8.24\n",
      "        10   1.41e+03       8.42\n",
      "\u001b[35mdone in 4.310 seconds\u001b[0m\n",
      "Expected: 0.686 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.364 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 902          |\n",
      "| EpRewMean               | 5.25         |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 8            |\n",
      "| TimeElapsed             | 5.03e+03     |\n",
      "| TimestepsSoFar          | 8192         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7739413    |\n",
      "| explained_variance_t... | -1.19e-07    |\n",
      "| meankl                  | 0.0010344823 |\n",
      "| optimgain               | 0.0020698907 |\n",
      "| surrgain                | 0.0020698907 |\n",
      "------------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=0.20 +/- 1.47\n",
      "Episode length: 847.40 +/- 941.50\n",
      "Eval num_timesteps=8192, episode_reward=0.20 +/- 1.47\n",
      "Episode length: 834.60 +/- 951.60\n",
      "\u001b[35mdone in 291.490 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.179 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        902          0\n",
      "         1      0.153   0.000652\n",
      "         2       6.87    0.00099\n",
      "         3        737      0.098\n",
      "         4       0.39       0.17\n",
      "         5   1.43e+03      0.403\n",
      "         6        518      0.641\n",
      "         7        1.4      0.696\n",
      "         8    2.5e+03       2.32\n",
      "         9       92.2       2.52\n",
      "        10       1.15       2.53\n",
      "\u001b[35mdone in 5.237 seconds\u001b[0m\n",
      "Expected: 0.131 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.525 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 1.01e+03     |\n",
      "| EpRewMean               | 6.33         |\n",
      "| EpThisIter              | 1            |\n",
      "| EpisodesSoFar           | 9            |\n",
      "| TimeElapsed             | 5.33e+03     |\n",
      "| TimestepsSoFar          | 9216         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.772142     |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.0024825847 |\n",
      "| optimgain               | 0.002599724  |\n",
      "| surrgain                | 0.002599724  |\n",
      "------------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=9216, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 681.785 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.141 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       7.04          0\n",
      "         1      0.385    0.00941\n",
      "         2       3.69       1.34\n",
      "         3        251       3.01\n",
      "         4       19.1       14.4\n",
      "         5       9.57       26.4\n",
      "         6       15.5       26.5\n",
      "         7       21.1       39.8\n",
      "         8        168         55\n",
      "         9       1.92       56.1\n",
      "        10     0.0485       56.9\n",
      "\u001b[35mdone in 5.187 seconds\u001b[0m\n",
      "Expected: 0.805 Actual: -0.001\n",
      "surrogate didn't improve. shrinking step.\n",
      "Expected: 0.805 Actual: 0.001\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.838 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 985           |\n",
      "| EpRewMean               | 6             |\n",
      "| EpThisIter              | 1             |\n",
      "| EpisodesSoFar           | 10            |\n",
      "| TimeElapsed             | 6.03e+03      |\n",
      "| TimestepsSoFar          | 10240         |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.7698405     |\n",
      "| explained_variance_t... | -1.19e-07     |\n",
      "| meankl                  | 0.00087610364 |\n",
      "| optimgain               | 0.00086033205 |\n",
      "| surrgain                | 0.00086033205 |\n",
      "-------------------------------------------\n",
      "Connecting to host 127.0.0.1 at port 49478 ...\n",
      "Client connected to server [OK]\n",
      "********** Iteration 0 ************\n",
      "Optimizing Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mats/anaconda3/lib/python3.7/site-packages/stable_baselines/common/callbacks.py:277: UserWarning: Training and eval env are not of the same type<TimeLimit<GVGAI_Env<gvgai-boulderdash-lvl3-v0>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x146e0b510>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=0, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=0, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 687.656 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.058 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0        587          0\n",
      "         1       3.58   0.000178\n",
      "         2       1.19   0.000249\n",
      "         3        124    0.00627\n",
      "         4      0.688    0.00741\n",
      "         5       6.52     0.0128\n",
      "         6       72.9     0.0138\n",
      "         7       28.3     0.0204\n",
      "         8       3.78     0.0256\n",
      "         9        430     0.0344\n",
      "        10      0.761     0.0474\n",
      "\u001b[35mdone in 4.907 seconds\u001b[0m\n",
      "Expected: 0.027 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.791 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 64.7         |\n",
      "| EpRewMean               | -1           |\n",
      "| EpThisIter              | 9            |\n",
      "| EpisodesSoFar           | 9            |\n",
      "| TimeElapsed             | 702          |\n",
      "| TimestepsSoFar          | 1024         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7681437    |\n",
      "| explained_variance_t... | 0.00842      |\n",
      "| meankl                  | 0.0014144855 |\n",
      "| optimgain               | 0.0030826083 |\n",
      "| surrgain                | 0.0030826083 |\n",
      "------------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=1024, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=1024, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 690.546 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.032 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       11.9          0\n",
      "         1         11    0.00455\n",
      "         2       18.1     0.0171\n",
      "         3     0.0946     0.0209\n",
      "         4      0.543      0.265\n",
      "         5      0.648      0.266\n",
      "         6       9.39      0.286\n",
      "         7       4.48       4.34\n",
      "         8       21.7       4.65\n",
      "         9       8.79        4.7\n",
      "        10        409       6.08\n",
      "\u001b[35mdone in 4.817 seconds\u001b[0m\n",
      "Expected: 0.183 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.640 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 64.7        |\n",
      "| EpRewMean               | -1          |\n",
      "| EpThisIter              | 0           |\n",
      "| EpisodesSoFar           | 9           |\n",
      "| TimeElapsed             | 1.41e+03    |\n",
      "| TimestepsSoFar          | 2048        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7698927   |\n",
      "| explained_variance_t... | -1.19e-07   |\n",
      "| meankl                  | 0.008314204 |\n",
      "| optimgain               | 0.002479338 |\n",
      "| surrgain                | 0.002479338 |\n",
      "-----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=2048, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=2048, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 677.732 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.698 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       87.6          0\n",
      "         1       1.45   0.000236\n",
      "         2       2.74   0.000265\n",
      "         3      0.453    0.00146\n",
      "         4        432      0.123\n",
      "         5       3.46      0.145\n",
      "         6       2.98      0.145\n",
      "         7       0.71      0.225\n",
      "         8       9.51      0.225\n",
      "         9        596      0.316\n",
      "        10       28.5      0.371\n",
      "\u001b[35mdone in 4.038 seconds\u001b[0m\n",
      "Expected: 0.063 Actual: 0.003\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.662 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 245          |\n",
      "| EpRewMean               | 0.182        |\n",
      "| EpThisIter              | 2            |\n",
      "| EpisodesSoFar           | 11           |\n",
      "| TimeElapsed             | 2.1e+03      |\n",
      "| TimestepsSoFar          | 3072         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7719109    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.002198971  |\n",
      "| optimgain               | 0.0029326645 |\n",
      "| surrgain                | 0.0029326645 |\n",
      "------------------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=3072, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=3072, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 680.532 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.693 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0         56          0\n",
      "         1       67.5    0.00141\n",
      "         2        0.3      0.172\n",
      "         3        422       0.21\n",
      "         4       1.11      0.346\n",
      "         5        113       1.34\n",
      "         6       4.47       1.36\n",
      "         7         54       12.5\n",
      "         8       22.8       12.5\n",
      "         9       46.7       25.9\n",
      "        10        248       25.9\n",
      "\u001b[35mdone in 3.902 seconds\u001b[0m\n",
      "Expected: 0.516 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.547 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 266           |\n",
      "| EpRewMean               | 0.769         |\n",
      "| EpThisIter              | 2             |\n",
      "| EpisodesSoFar           | 13            |\n",
      "| TimeElapsed             | 2.79e+03      |\n",
      "| TimestepsSoFar          | 4096          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.7701793     |\n",
      "| explained_variance_t... | 5.96e-08      |\n",
      "| meankl                  | 0.00079629186 |\n",
      "| optimgain               | 0.0023078965  |\n",
      "| surrgain                | 0.0023078965  |\n",
      "-------------------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=4096, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=4096, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 691.815 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.677 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0       0.14          0\n",
      "         1     0.0503     0.0113\n",
      "         2    0.00428     0.0405\n",
      "         3    0.00267     0.0527\n",
      "         4     0.0137      0.256\n",
      "         5    0.00791      0.268\n",
      "         6   0.000352      0.295\n",
      "         7    0.00238      0.309\n",
      "         8     0.0444      0.566\n",
      "         9    0.00122      0.632\n",
      "        10   0.000478      0.653\n",
      "\u001b[35mdone in 3.924 seconds\u001b[0m\n",
      "Expected: 0.025 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.547 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 294          |\n",
      "| EpRewMean               | 1.31         |\n",
      "| EpThisIter              | 3            |\n",
      "| EpisodesSoFar           | 16           |\n",
      "| TimeElapsed             | 3.5e+03      |\n",
      "| TimestepsSoFar          | 5120         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7580068    |\n",
      "| explained_variance_t... | 5.96e-08     |\n",
      "| meankl                  | 0.003919418  |\n",
      "| optimgain               | 0.0023540847 |\n",
      "| surrgain                | 0.0023540847 |\n",
      "------------------------------------------\n",
      "********** Iteration 5 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=5120, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=5120, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 667.258 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.829 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0202          0\n",
      "         1   0.000518      0.021\n",
      "         2   4.65e-06     0.0221\n",
      "         3   7.74e-09     0.0222\n",
      "         4   1.93e-10     0.0222\n",
      "         5   1.49e-14     0.0222\n",
      "\u001b[35mdone in 2.306 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.857 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 309          |\n",
      "| EpRewMean               | 1.47         |\n",
      "| EpThisIter              | 3            |\n",
      "| EpisodesSoFar           | 19           |\n",
      "| TimeElapsed             | 4.18e+03     |\n",
      "| TimestepsSoFar          | 6144         |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7314639    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.010112523  |\n",
      "| optimgain               | 0.0079901675 |\n",
      "| surrgain                | 0.0079901675 |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 6 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=6144, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=6144, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 698.956 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 2.155 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0164          0\n",
      "         1     0.0013     0.0284\n",
      "         2   1.01e-05     0.0302\n",
      "         3   6.88e-08     0.0302\n",
      "         4    3.2e-10     0.0302\n",
      "         5   1.26e-14     0.0302\n",
      "\u001b[35mdone in 2.333 seconds\u001b[0m\n",
      "Expected: 0.009 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.927 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 311         |\n",
      "| EpRewMean               | 1.65        |\n",
      "| EpThisIter              | 4           |\n",
      "| EpisodesSoFar           | 23          |\n",
      "| TimeElapsed             | 4.89e+03    |\n",
      "| TimestepsSoFar          | 7168        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.7098378   |\n",
      "| explained_variance_t... | 0           |\n",
      "| meankl                  | 0.009649633 |\n",
      "| optimgain               | 0.008281111 |\n",
      "| surrgain                | 0.008281111 |\n",
      "-----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=7168, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=7168, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 682.931 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.788 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0206          0\n",
      "         1    0.00169     0.0206\n",
      "         2   0.000172     0.0255\n",
      "         3   5.77e-07     0.0262\n",
      "         4   3.09e-08     0.0262\n",
      "         5   1.34e-14     0.0262\n",
      "\u001b[35mdone in 2.090 seconds\u001b[0m\n",
      "Expected: 0.008 Actual: 0.008\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 5.888 seconds\u001b[0m\n",
      "-----------------------------------------\n",
      "| EpLenMean               | 320         |\n",
      "| EpRewMean               | 1.92        |\n",
      "| EpThisIter              | 2           |\n",
      "| EpisodesSoFar           | 25          |\n",
      "| TimeElapsed             | 5.58e+03    |\n",
      "| TimestepsSoFar          | 8192        |\n",
      "| entloss                 | 0.0         |\n",
      "| entropy                 | 1.717498    |\n",
      "| explained_variance_t... | 1.19e-07    |\n",
      "| meankl                  | 0.010065949 |\n",
      "| optimgain               | 0.008328581 |\n",
      "| surrgain                | 0.008328581 |\n",
      "-----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=8192, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=8192, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 683.674 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 1.912 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0161          0\n",
      "         1    0.00158     0.0196\n",
      "         2    0.00303     0.0371\n",
      "         3    0.00969      0.114\n",
      "         4     0.0869      0.902\n",
      "         5     0.0175       2.84\n",
      "         6   4.07e-10       2.99\n",
      "         7   3.07e-11       2.99\n",
      "\u001b[35mdone in 3.084 seconds\u001b[0m\n",
      "Expected: 0.043 Actual: 0.001\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 9.137 seconds\u001b[0m\n",
      "-------------------------------------------\n",
      "| EpLenMean               | 317           |\n",
      "| EpRewMean               | 2.04          |\n",
      "| EpThisIter              | 3             |\n",
      "| EpisodesSoFar           | 28            |\n",
      "| TimeElapsed             | 6.28e+03      |\n",
      "| TimestepsSoFar          | 9216          |\n",
      "| entloss                 | 0.0           |\n",
      "| entropy                 | 1.7115328     |\n",
      "| explained_variance_t... | 0             |\n",
      "| meankl                  | 0.00027142063 |\n",
      "| optimgain               | 0.0011553532  |\n",
      "| surrgain                | 0.0011553532  |\n",
      "-------------------------------------------\n",
      "********** Iteration 9 ************\n",
      "Optimizing Policy...\n",
      "\u001b[35msampling\u001b[0m\n",
      "Eval num_timesteps=9216, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "Eval num_timesteps=9216, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "\u001b[35mdone in 665.888 seconds\u001b[0m\n",
      "\u001b[35mcomputegrad\u001b[0m\n",
      "\u001b[35mdone in 3.140 seconds\u001b[0m\n",
      "\u001b[35mconjugate_gradient\u001b[0m\n",
      "      iter residual norm  soln norm\n",
      "         0     0.0439          0\n",
      "         1      0.112      0.139\n",
      "         2       2.72       3.71\n",
      "         3       2.68       12.2\n",
      "         4      0.692       16.8\n",
      "         5     0.0739       17.6\n",
      "         6   1.33e-09       17.7\n",
      "         7      3e-10       17.7\n",
      "         8   9.05e-10       17.7\n",
      "         9   9.96e-09       17.7\n",
      "        10   1.77e-08       17.7\n",
      "\u001b[35mdone in 6.126 seconds\u001b[0m\n",
      "Expected: 0.250 Actual: 0.002\n",
      "Stepsize OK!\n",
      "\u001b[35mvf\u001b[0m\n",
      "\u001b[35mdone in 6.399 seconds\u001b[0m\n",
      "------------------------------------------\n",
      "| EpLenMean               | 316          |\n",
      "| EpRewMean               | 2            |\n",
      "| EpThisIter              | 3            |\n",
      "| EpisodesSoFar           | 31           |\n",
      "| TimeElapsed             | 6.97e+03     |\n",
      "| TimestepsSoFar          | 10240        |\n",
      "| entloss                 | 0.0          |\n",
      "| entropy                 | 1.7202562    |\n",
      "| explained_variance_t... | 0            |\n",
      "| meankl                  | 0.0009165523 |\n",
      "| optimgain               | 0.00178794   |\n",
      "| surrgain                | 0.00178794   |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import gym_gvgai\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import ActorCriticPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import SAC\n",
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import TRPO\n",
    "\n",
    "\n",
    "def show_state(env, step=0, name=\"\", info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name,step,info))\n",
    "    plt.axis('off')\n",
    "              \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    \n",
    "env = gym.make('gvgai-boulderdash-lvl2-v0')\n",
    "\n",
    "    \n",
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "log_path='./logs/', eval_freq=500,\n",
    "deterministic=True, render=False)\n",
    "\n",
    "\n",
    "\n",
    "model = TRPO(MlpPolicy,env,verbose=1)\n",
    "model.load(\"TRPO_boulder\")\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_boulder\")\n",
    "\n",
    "\n",
    "        \n",
    "env.close()\n",
    "\n",
    "env = gym.make('gvgai-boulderdash-lvl3-v0')\n",
    "\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=10000,callback=eval_callback)\n",
    "model.save(\"TRPO_boulder\")\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
